# UAV-weed-detection-paper
Code for the Paper: Lu et al., Weed Instance Segmentation from UAV Orthomosaic Images based on Deep Learning. 

Data are avaible on [Zonedo](https://zenodo.org/records/15229621?token=eyJhbGciOiJIUzUxMiJ9.eyJpZCI6IjI5YTIyMjZiLWFlY2EtNGQ4ZS04ZGFlLTkwZmRmZDdjMjMzOSIsImRhdGEiOnt9LCJyYW5kb20iOiIzY2JjYjYyOGU0MzIwNjkzZWM1YTQ5NzI3MzI1ZmE5NCJ9.ADWAkTykO82BiJiyEckPNgazRLPbq3Fywpkq5N93FUlTFCFrOimy83E1Nv6Kprz6PvFAK8nRr_6F9YgHofNBRAlink:)

## Dataset
**annotation_json_raw** folder is the raw annotations generated by [Anylabeling](https://github.com/vietanhdev/anylabeling.git)

**yolo_format** folder is for yolo training, it is transformed by script: code/yolo/json2yolo.py.

yolo_format/SR&SR_multi are super resolution reconstructed by Real-ESRGAN with [Waifu2x-Extension-GUI](https://github.com/AaronFeng753/Waifu2x-Extension-GUI.git)

**maskrcnn_format** folder is for maskrcnn training, it is transformed by a script within json2coco.zip 

**plots_img** folder is the images with the plot size, they are cropped from the orthomosaic, size is 1000*3000 pixels

## Training and prediction
**yolov8** was trained with [ultralytics](https://github.com/ultralytics/ultralytics)

**Mask RCNN** was trained with [Detection2](https://github.com/facebookresearch/detectron2.git)

## Results
The results include the trained weights, parameters, and evaluation. Weight of Mask RCNN was too large, I attached it in the release.

results/yolo/predict/predict_plots_both was predicted by results/yolo/train/SR/weights/best.pt  
We used yolov8 to segment the potatoes and weeds in each plot. The .txt file in results\yolo\predict\predict_plots_both\labels  contains the coordinate information of each object. We used code\yolo\mask_area.py to calculate the coverage area of ​​potatoes and weeds in each plot.  
Finally, multiple linear regression is performed through code\yolo\regression.py.
