[03/19 18:17:02] detectron2 INFO: Rank of current process: 0. World size: 1
[03/19 18:17:02] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
numpy                            1.24.3
detectron2                       0.6 @/home/lu/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Ti (arch=8.6)
Driver version                   545.29.06
CUDA_HOME                        None - invalid!
Pillow                           10.2.0
torchvision                      0.17.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision
torchvision arch flags           /home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[03/19 18:17:02] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[03/19 18:17:02] detectron2 INFO: Contents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[03/19 18:17:02] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_my_val
  TRAIN:
  - coco_my_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 640
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 512
  - 768
  MIN_SIZE_TRAIN_SAMPLING: range
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 3
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 199
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 2399
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 7000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 200
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/19 18:17:02] detectron2 INFO: Full config saved to ./output/config.yaml
[03/19 18:17:02] d2.utils.env INFO: Using a generated random seed 2539256
[03/19 18:17:02] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/19 18:17:02] d2.data.build WARNING: The following dataset names are not registered in the DatasetCatalog: {'coco_my_train'}. Available datasets are KeysView(DatasetCatalog(registered datasets: coco_2014_train, coco_2014_val, coco_2014_minival, coco_2014_valminusminival, coco_2017_train, coco_2017_val, coco_2017_test, coco_2017_test-dev, coco_2017_val_100, keypoints_coco_2014_train, keypoints_coco_2014_val, keypoints_coco_2014_minival, keypoints_coco_2014_valminusminival, keypoints_coco_2017_train, keypoints_coco_2017_val, keypoints_coco_2017_val_100, coco_2017_train_panoptic_separated, coco_2017_train_panoptic_stuffonly, coco_2017_train_panoptic, coco_2017_val_panoptic_separated, coco_2017_val_panoptic_stuffonly, coco_2017_val_panoptic, coco_2017_val_100_panoptic_separated, coco_2017_val_100_panoptic_stuffonly, coco_2017_val_100_panoptic, lvis_v1_train, lvis_v1_val, lvis_v1_test_dev, lvis_v1_test_challenge, lvis_v0.5_train, lvis_v0.5_val, lvis_v0.5_val_rand_100, lvis_v0.5_test, lvis_v0.5_train_cocofied, lvis_v0.5_val_cocofied, cityscapes_fine_instance_seg_train, cityscapes_fine_sem_seg_train, cityscapes_fine_instance_seg_val, cityscapes_fine_sem_seg_val, cityscapes_fine_instance_seg_test, cityscapes_fine_sem_seg_test, cityscapes_fine_panoptic_train, cityscapes_fine_panoptic_val, voc_2007_trainval, voc_2007_train, voc_2007_val, voc_2007_test, voc_2012_trainval, voc_2012_train, voc_2012_val, ade20k_sem_seg_train, ade20k_sem_seg_val))
[03/19 21:20:03] detectron2 INFO: Rank of current process: 0. World size: 1
[03/19 21:20:03] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
numpy                            1.24.3
detectron2                       0.6 @/home/lu/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Ti (arch=8.6)
Driver version                   545.29.06
CUDA_HOME                        None - invalid!
Pillow                           10.2.0
torchvision                      0.17.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision
torchvision arch flags           /home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[03/19 21:20:03] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[03/19 21:20:03] detectron2 INFO: Contents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[03/19 21:20:03] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_my_val
  TRAIN:
  - coco_my_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 640
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 512
  - 768
  MIN_SIZE_TRAIN_SAMPLING: range
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 3
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 199
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 2399
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 7000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 200
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/19 21:20:03] detectron2 INFO: Full config saved to ./output/config.yaml
[03/19 21:20:03] d2.utils.env INFO: Using a generated random seed 3952601
[03/19 21:20:04] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/19 21:20:04] d2.data.datasets.coco INFO: Loaded 130 images in COCO format from /home/lu/detectron2/potato/COCOformat/train.json
[03/19 21:20:04] d2.data.build INFO: Removed 0 images with no usable annotations. 130 images left.
[03/19 21:20:04] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |
|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| __backgroun.. | 659          |   potato   | 934          |    weed    | 0            |
|               |              |            |              |            |              |
|     total     | 1593         |            |              |            |              |[0m
[03/19 21:20:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.9, 0.9]), ResizeShortestEdge(short_edge_length=(512, 768), max_size=640), RandomFlip()]
[03/19 21:20:04] d2.data.build INFO: Using training sampler TrainingSampler
[03/19 21:20:04] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:20:04] d2.data.common INFO: Serializing 130 elements to byte tensors and concatenating them all ...
[03/19 21:20:04] d2.data.common INFO: Serialized dataset takes 0.61 MiB
[03/19 21:20:04] d2.data.build INFO: Making batched data loader with batch_size=4
[03/19 21:20:04] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[03/19 21:20:04] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:20:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:20:12] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/19 21:20:12] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up - Total num: 54
[03/19 21:20:12] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.{bias, weight}[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[03/19 21:20:12] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/19 21:20:12] d2.engine.train_loop INFO: Starting training from iteration 0
[03/19 21:20:12] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/home/lu/detectron2/detectron2/engine/defaults.py", line 496, in run_step
    self._trainer.run_step()
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 297, in run_step
    data = next(self._data_loader_iter)
  File "/home/lu/detectron2/detectron2/data/common.py", line 329, in __iter__
    for d in self.dataset:
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/_utils.py", line 722, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 32, in fetch
    data.append(next(self.dataset_iter))
  File "/home/lu/detectron2/detectron2/data/common.py", line 296, in __iter__
    yield self.dataset[idx]
  File "/home/lu/detectron2/detectron2/data/common.py", line 125, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/lu/detectron2/detectron2/utils/serialize.py", line 26, in __call__
    return self._obj(*args, **kwargs)
  File "/home/lu/detectron2/detectron2/data/dataset_mapper.py", line 154, in __call__
    image = utils.read_image(dataset_dict["file_name"], format=self.image_format)
  File "/home/lu/detectron2/detectron2/data/detection_utils.py", line 180, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/iopath/common/file_io.py", line 1012, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/iopath/common/file_io.py", line 604, in _open
    return open(  # type: ignore
FileNotFoundError: [Errno 2] No such file or directory: '/home/lu/detectron2/potato/JPEGImages/..\\after_crop\\tile_8_5.jpg'

[03/19 21:20:12] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/19 21:20:12] d2.utils.events INFO:  iter: 0       lr: N/A  max_mem: 173M
[03/19 21:26:45] detectron2 INFO: Rank of current process: 0. World size: 1
[03/19 21:26:46] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
numpy                            1.24.3
detectron2                       0.6 @/home/lu/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Ti (arch=8.6)
Driver version                   545.29.06
CUDA_HOME                        None - invalid!
Pillow                           10.2.0
torchvision                      0.17.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision
torchvision arch flags           /home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[03/19 21:26:46] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[03/19 21:26:46] detectron2 INFO: Contents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[03/19 21:26:46] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_my_val
  TRAIN:
  - coco_my_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 640
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 512
  - 768
  MIN_SIZE_TRAIN_SAMPLING: range
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 3
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 199
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 2399
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 7000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 200
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/19 21:26:46] detectron2 INFO: Full config saved to ./output/config.yaml
[03/19 21:26:46] d2.utils.env INFO: Using a generated random seed 46175399
[03/19 21:26:46] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/19 21:26:46] d2.data.datasets.coco INFO: Loaded 130 images in COCO format from /home/lu/detectron2/potato/COCOformat/train.json
[03/19 21:26:46] d2.data.build INFO: Removed 0 images with no usable annotations. 130 images left.
[03/19 21:26:46] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |
|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| __backgroun.. | 659          |   potato   | 934          |    weed    | 0            |
|               |              |            |              |            |              |
|     total     | 1593         |            |              |            |              |[0m
[03/19 21:26:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.9, 0.9]), ResizeShortestEdge(short_edge_length=(512, 768), max_size=640), RandomFlip()]
[03/19 21:26:46] d2.data.build INFO: Using training sampler TrainingSampler
[03/19 21:26:46] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:26:46] d2.data.common INFO: Serializing 130 elements to byte tensors and concatenating them all ...
[03/19 21:26:46] d2.data.common INFO: Serialized dataset takes 0.61 MiB
[03/19 21:26:46] d2.data.build INFO: Making batched data loader with batch_size=4
[03/19 21:26:46] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[03/19 21:26:46] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:26:46] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:26:46] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/19 21:26:46] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up - Total num: 54
[03/19 21:26:46] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.{bias, weight}[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[03/19 21:26:46] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/19 21:26:46] d2.engine.train_loop INFO: Starting training from iteration 0
[03/19 21:26:51] d2.utils.events INFO:  eta: 0:08:35  iter: 19  total_loss: 5.396  loss_cls: 3.697  loss_box_reg: 0.06281  loss_mask: 0.6928  loss_rpn_cls: 0.7003  loss_rpn_loc: 0.2843    time: 0.2155  last_time: 0.2168  data_time: 0.0115  last_data_time: 0.0032   lr: 3.9962e-05  max_mem: 2144M
[03/19 21:26:56] d2.utils.events INFO:  eta: 0:08:31  iter: 39  total_loss: 2.226  loss_cls: 0.4406  loss_box_reg: 0.06396  loss_mask: 0.6797  loss_rpn_cls: 0.6803  loss_rpn_loc: 0.3002    time: 0.2194  last_time: 0.2475  data_time: 0.0032  last_data_time: 0.0031   lr: 7.9922e-05  max_mem: 2186M
[03/19 21:27:01] d2.utils.events INFO:  eta: 0:08:43  iter: 59  total_loss: 2.123  loss_cls: 0.5415  loss_box_reg: 0.1159  loss_mask: 0.6641  loss_rpn_cls: 0.6117  loss_rpn_loc: 0.2354    time: 0.2275  last_time: 0.2545  data_time: 0.0033  last_data_time: 0.0036   lr: 0.00011988  max_mem: 2186M
[03/19 21:27:06] d2.utils.events INFO:  eta: 0:09:11  iter: 79  total_loss: 1.849  loss_cls: 0.3058  loss_box_reg: 0.1528  loss_mask: 0.6586  loss_rpn_cls: 0.547  loss_rpn_loc: 0.2827    time: 0.2347  last_time: 0.2661  data_time: 0.0032  last_data_time: 0.0029   lr: 0.00015984  max_mem: 2250M
[03/19 21:27:11] d2.utils.events INFO:  eta: 0:09:17  iter: 99  total_loss: 1.922  loss_cls: 0.2917  loss_box_reg: 0.2356  loss_mask: 0.6609  loss_rpn_cls: 0.4675  loss_rpn_loc: 0.2726    time: 0.2398  last_time: 0.2581  data_time: 0.0034  last_data_time: 0.0032   lr: 0.0001998  max_mem: 2429M
[03/19 21:27:16] d2.utils.events INFO:  eta: 0:09:15  iter: 119  total_loss: 1.737  loss_cls: 0.2528  loss_box_reg: 0.2404  loss_mask: 0.6475  loss_rpn_cls: 0.3643  loss_rpn_loc: 0.2352    time: 0.2406  last_time: 0.2438  data_time: 0.0033  last_data_time: 0.0036   lr: 0.00023976  max_mem: 2441M
[03/19 21:27:21] d2.utils.events INFO:  eta: 0:09:09  iter: 139  total_loss: 1.611  loss_cls: 0.2374  loss_box_reg: 0.2855  loss_mask: 0.6441  loss_rpn_cls: 0.2619  loss_rpn_loc: 0.2066    time: 0.2412  last_time: 0.2768  data_time: 0.0034  last_data_time: 0.0035   lr: 0.00027972  max_mem: 2622M
[03/19 21:27:26] d2.utils.events INFO:  eta: 0:09:12  iter: 159  total_loss: 1.838  loss_cls: 0.2971  loss_box_reg: 0.4152  loss_mask: 0.6302  loss_rpn_cls: 0.2048  loss_rpn_loc: 0.2145    time: 0.2438  last_time: 0.2917  data_time: 0.0033  last_data_time: 0.0039   lr: 0.00031968  max_mem: 2702M
[03/19 21:27:32] d2.utils.events INFO:  eta: 0:09:15  iter: 179  total_loss: 1.944  loss_cls: 0.3291  loss_box_reg: 0.5753  loss_mask: 0.6323  loss_rpn_cls: 0.1751  loss_rpn_loc: 0.1935    time: 0.2483  last_time: 0.2920  data_time: 0.0036  last_data_time: 0.0039   lr: 0.00035964  max_mem: 3010M
[03/19 21:27:37] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000198.pth
[03/19 21:27:38] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:27:38] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |
|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| __backgroun.. | 82           |   potato   | 138          |    weed    | 0            |
|               |              |            |              |            |              |
|     total     | 220          |            |              |            |              |[0m
[03/19 21:27:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:27:38] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:27:38] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:27:38] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:27:38] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:27:39] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0366 s/iter. Eval: 0.0377 s/iter. Total: 0.0748 s/iter. ETA=0:00:00
[03/19 21:27:39] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.204013 (0.080268 s / iter per device, on 1 devices)
[03/19 21:27:39] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.036661 s / iter per device, on 1 devices)
[03/19 21:27:40] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:27:40] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:27:40] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:27:40] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:27:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:27:40] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:27:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:27:40] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 16.352 | 50.248 | 3.497  | 13.108 | 20.565 | 20.311 |
[03/19 21:27:40] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 156, in train
    self.after_step()
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 190, in after_step
    h.after_step()
  File "/home/lu/detectron2/detectron2/engine/hooks.py", line 556, in after_step
    self._do_eval()
  File "/home/lu/detectron2/detectron2/engine/hooks.py", line 529, in _do_eval
    results = self._func()
  File "/home/lu/detectron2/detectron2/engine/defaults.py", line 455, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/home/lu/detectron2/detectron2/engine/defaults.py", line 619, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/home/lu/detectron2/detectron2/evaluation/evaluator.py", line 213, in inference_on_dataset
    results = evaluator.evaluate()
  File "/home/lu/detectron2/detectron2/evaluation/coco_evaluation.py", line 206, in evaluate
    self._eval_predictions(predictions, img_ids=img_ids)
  File "/home/lu/detectron2/detectron2/evaluation/coco_evaluation.py", line 279, in _eval_predictions
    res = self._derive_coco_results(
  File "/home/lu/detectron2/detectron2/evaluation/coco_evaluation.py", line 364, in _derive_coco_results
    assert len(class_names) == precisions.shape[2]
AssertionError
[03/19 21:27:40] d2.engine.hooks INFO: Overall training speed: 197 iterations in 0:00:50 (0.2539 s / it)
[03/19 21:27:40] d2.engine.hooks INFO: Total training time: 0:00:52 (0:00:02 on hooks)
[03/19 21:27:40] d2.utils.events INFO:  eta: 0:09:14  iter: 199  total_loss: 1.797  loss_cls: 0.297  loss_box_reg: 0.5607  loss_mask: 0.6028  loss_rpn_cls: 0.1527  loss_rpn_loc: 0.1859    time: 0.2526  last_time: 0.2886  data_time: 0.0035  last_data_time: 0.0032   lr: 0.0003996  max_mem: 3128M
[03/19 21:31:34] detectron2 INFO: Rank of current process: 0. World size: 1
[03/19 21:31:35] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
numpy                            1.24.3
detectron2                       0.6 @/home/lu/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Ti (arch=8.6)
Driver version                   545.29.06
CUDA_HOME                        None - invalid!
Pillow                           10.2.0
torchvision                      0.17.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision
torchvision arch flags           /home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[03/19 21:31:35] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[03/19 21:31:35] detectron2 INFO: Contents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[03/19 21:31:35] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_my_val
  TRAIN:
  - coco_my_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 640
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 512
  - 768
  MIN_SIZE_TRAIN_SAMPLING: range
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 3
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 199
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 2399
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 7000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 200
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/19 21:31:35] detectron2 INFO: Full config saved to ./output/config.yaml
[03/19 21:31:35] d2.utils.env INFO: Using a generated random seed 35158321
[03/19 21:31:35] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/19 21:31:35] d2.data.build WARNING: The following dataset names are not registered in the DatasetCatalog: {'coco_my_train'}. Available datasets are KeysView(DatasetCatalog(registered datasets: coco_2014_train, coco_2014_val, coco_2014_minival, coco_2014_valminusminival, coco_2017_train, coco_2017_val, coco_2017_test, coco_2017_test-dev, coco_2017_val_100, keypoints_coco_2014_train, keypoints_coco_2014_val, keypoints_coco_2014_minival, keypoints_coco_2014_valminusminival, keypoints_coco_2017_train, keypoints_coco_2017_val, keypoints_coco_2017_val_100, coco_2017_train_panoptic_separated, coco_2017_train_panoptic_stuffonly, coco_2017_train_panoptic, coco_2017_val_panoptic_separated, coco_2017_val_panoptic_stuffonly, coco_2017_val_panoptic, coco_2017_val_100_panoptic_separated, coco_2017_val_100_panoptic_stuffonly, coco_2017_val_100_panoptic, lvis_v1_train, lvis_v1_val, lvis_v1_test_dev, lvis_v1_test_challenge, lvis_v0.5_train, lvis_v0.5_val, lvis_v0.5_val_rand_100, lvis_v0.5_test, lvis_v0.5_train_cocofied, lvis_v0.5_val_cocofied, cityscapes_fine_instance_seg_train, cityscapes_fine_sem_seg_train, cityscapes_fine_instance_seg_val, cityscapes_fine_sem_seg_val, cityscapes_fine_instance_seg_test, cityscapes_fine_sem_seg_test, cityscapes_fine_panoptic_train, cityscapes_fine_panoptic_val, voc_2007_trainval, voc_2007_train, voc_2007_val, voc_2007_test, voc_2012_trainval, voc_2012_train, voc_2012_val, ade20k_sem_seg_train, ade20k_sem_seg_val))
[03/19 21:31:47] detectron2 INFO: Rank of current process: 0. World size: 1
[03/19 21:31:47] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
numpy                            1.24.3
detectron2                       0.6 @/home/lu/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Ti (arch=8.6)
Driver version                   545.29.06
CUDA_HOME                        None - invalid!
Pillow                           10.2.0
torchvision                      0.17.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision
torchvision arch flags           /home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[03/19 21:31:47] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[03/19 21:31:47] detectron2 INFO: Contents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[03/19 21:31:47] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_my_val
  TRAIN:
  - coco_my_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 640
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 512
  - 768
  MIN_SIZE_TRAIN_SAMPLING: range
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 3
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 199
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 2399
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 7000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 200
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/19 21:31:47] detectron2 INFO: Full config saved to ./output/config.yaml
[03/19 21:31:48] d2.utils.env INFO: Using a generated random seed 48051395
[03/19 21:31:48] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/19 21:31:48] d2.data.datasets.coco INFO: Loaded 130 images in COCO format from /home/lu/detectron2/potato/COCOformat/train.json
[03/19 21:31:48] d2.data.build INFO: Removed 0 images with no usable annotations. 130 images left.
[03/19 21:31:48] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |
|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| __backgroun.. | 659          |   potato   | 934          |    weed    | 0            |
|               |              |            |              |            |              |
|     total     | 1593         |            |              |            |              |[0m
[03/19 21:31:48] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.9, 0.9]), ResizeShortestEdge(short_edge_length=(512, 768), max_size=640), RandomFlip()]
[03/19 21:31:48] d2.data.build INFO: Using training sampler TrainingSampler
[03/19 21:31:48] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:31:48] d2.data.common INFO: Serializing 130 elements to byte tensors and concatenating them all ...
[03/19 21:31:48] d2.data.common INFO: Serialized dataset takes 0.61 MiB
[03/19 21:31:48] d2.data.build INFO: Making batched data loader with batch_size=4
[03/19 21:31:48] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[03/19 21:31:48] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:31:48] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:31:48] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/19 21:31:48] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up - Total num: 54
[03/19 21:31:48] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.{bias, weight}[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[03/19 21:31:48] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/19 21:31:48] d2.engine.train_loop INFO: Starting training from iteration 0
[03/19 21:31:53] d2.utils.events INFO:  eta: 0:08:47  iter: 19  total_loss: 5.326  loss_cls: 3.625  loss_box_reg: 0.07701  loss_mask: 0.6903  loss_rpn_cls: 0.6779  loss_rpn_loc: 0.3353    time: 0.2233  last_time: 0.2271  data_time: 0.0104  last_data_time: 0.0033   lr: 3.9962e-05  max_mem: 2084M
[03/19 21:31:58] d2.utils.events INFO:  eta: 0:08:46  iter: 39  total_loss: 2.211  loss_cls: 0.5143  loss_box_reg: 0.09988  loss_mask: 0.6745  loss_rpn_cls: 0.6537  loss_rpn_loc: 0.266    time: 0.2251  last_time: 0.2304  data_time: 0.0031  last_data_time: 0.0032   lr: 7.9922e-05  max_mem: 2107M
[03/19 21:32:02] d2.utils.events INFO:  eta: 0:08:48  iter: 59  total_loss: 2.178  loss_cls: 0.4864  loss_box_reg: 0.09901  loss_mask: 0.6673  loss_rpn_cls: 0.6185  loss_rpn_loc: 0.2747    time: 0.2265  last_time: 0.2235  data_time: 0.0030  last_data_time: 0.0028   lr: 0.00011988  max_mem: 2149M
[03/19 21:32:07] d2.utils.events INFO:  eta: 0:08:40  iter: 79  total_loss: 1.968  loss_cls: 0.3183  loss_box_reg: 0.1273  loss_mask: 0.6597  loss_rpn_cls: 0.5658  loss_rpn_loc: 0.2555    time: 0.2258  last_time: 0.2233  data_time: 0.0033  last_data_time: 0.0041   lr: 0.00015984  max_mem: 2161M
[03/19 21:32:11] d2.utils.events INFO:  eta: 0:08:39  iter: 99  total_loss: 1.833  loss_cls: 0.3013  loss_box_reg: 0.2147  loss_mask: 0.6528  loss_rpn_cls: 0.4614  loss_rpn_loc: 0.2253    time: 0.2265  last_time: 0.2219  data_time: 0.0034  last_data_time: 0.0035   lr: 0.0001998  max_mem: 2310M
[03/19 21:32:16] d2.utils.events INFO:  eta: 0:08:35  iter: 119  total_loss: 1.721  loss_cls: 0.2743  loss_box_reg: 0.2225  loss_mask: 0.638  loss_rpn_cls: 0.3724  loss_rpn_loc: 0.2229    time: 0.2267  last_time: 0.2259  data_time: 0.0034  last_data_time: 0.0033   lr: 0.00023976  max_mem: 2310M
[03/19 21:32:20] d2.utils.events INFO:  eta: 0:08:30  iter: 139  total_loss: 1.693  loss_cls: 0.2632  loss_box_reg: 0.2377  loss_mask: 0.637  loss_rpn_cls: 0.3082  loss_rpn_loc: 0.2496    time: 0.2264  last_time: 0.2353  data_time: 0.0033  last_data_time: 0.0032   lr: 0.00027972  max_mem: 2444M
[03/19 21:32:25] d2.utils.events INFO:  eta: 0:08:27  iter: 159  total_loss: 1.69  loss_cls: 0.2728  loss_box_reg: 0.3315  loss_mask: 0.6211  loss_rpn_cls: 0.1957  loss_rpn_loc: 0.1782    time: 0.2277  last_time: 0.2618  data_time: 0.0033  last_data_time: 0.0028   lr: 0.00031968  max_mem: 2579M
[03/19 21:32:30] d2.utils.events INFO:  eta: 0:08:25  iter: 179  total_loss: 1.785  loss_cls: 0.299  loss_box_reg: 0.4485  loss_mask: 0.6142  loss_rpn_cls: 0.1703  loss_rpn_loc: 0.1994    time: 0.2302  last_time: 0.2685  data_time: 0.0031  last_data_time: 0.0031   lr: 0.00035964  max_mem: 2653M
[03/19 21:32:35] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000198.pth
[03/19 21:32:36] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:32:36] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |
|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| __backgroun.. | 82           |   potato   | 138          |    weed    | 0            |
|               |              |            |              |            |              |
|     total     | 220          |            |              |            |              |[0m
[03/19 21:32:36] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:32:36] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:32:36] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:32:36] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:32:36] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:32:37] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0338 s/iter. Eval: 0.0339 s/iter. Total: 0.0682 s/iter. ETA=0:00:00
[03/19 21:32:37] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.090904 (0.072727 s / iter per device, on 1 devices)
[03/19 21:32:37] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.034330 s / iter per device, on 1 devices)
[03/19 21:32:37] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:32:37] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:32:37] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:32:37] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:32:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:32:37] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:32:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:32:37] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 16.832 | 52.242 | 4.560  | 14.981 | 17.589 | 15.330 |
[03/19 21:32:37] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 156, in train
    self.after_step()
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 190, in after_step
    h.after_step()
  File "/home/lu/detectron2/detectron2/engine/hooks.py", line 556, in after_step
    self._do_eval()
  File "/home/lu/detectron2/detectron2/engine/hooks.py", line 529, in _do_eval
    results = self._func()
  File "/home/lu/detectron2/detectron2/engine/defaults.py", line 455, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/home/lu/detectron2/detectron2/engine/defaults.py", line 619, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/home/lu/detectron2/detectron2/evaluation/evaluator.py", line 213, in inference_on_dataset
    results = evaluator.evaluate()
  File "/home/lu/detectron2/detectron2/evaluation/coco_evaluation.py", line 206, in evaluate
    self._eval_predictions(predictions, img_ids=img_ids)
  File "/home/lu/detectron2/detectron2/evaluation/coco_evaluation.py", line 279, in _eval_predictions
    res = self._derive_coco_results(
  File "/home/lu/detectron2/detectron2/evaluation/coco_evaluation.py", line 364, in _derive_coco_results
    assert len(class_names) == precisions.shape[2]
AssertionError
[03/19 21:32:37] d2.engine.hooks INFO: Overall training speed: 197 iterations in 0:00:46 (0.2357 s / it)
[03/19 21:32:37] d2.engine.hooks INFO: Total training time: 0:00:48 (0:00:02 on hooks)
[03/19 21:32:37] d2.utils.events INFO:  eta: 0:08:24  iter: 199  total_loss: 1.869  loss_cls: 0.3139  loss_box_reg: 0.5918  loss_mask: 0.61  loss_rpn_cls: 0.1499  loss_rpn_loc: 0.1941    time: 0.2345  last_time: 0.2635  data_time: 0.0033  last_data_time: 0.0051   lr: 0.0003996  max_mem: 2921M
[03/19 21:35:34] detectron2 INFO: Rank of current process: 0. World size: 1
[03/19 21:35:34] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
numpy                            1.24.3
detectron2                       0.6 @/home/lu/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Ti (arch=8.6)
Driver version                   545.29.06
CUDA_HOME                        None - invalid!
Pillow                           10.2.0
torchvision                      0.17.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision
torchvision arch flags           /home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[03/19 21:35:34] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[03/19 21:35:34] detectron2 INFO: Contents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[03/19 21:35:34] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_my_val
  TRAIN:
  - coco_my_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 640
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 512
  - 768
  MIN_SIZE_TRAIN_SAMPLING: range
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 2
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 199
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 2399
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 7000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 200
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/19 21:35:34] detectron2 INFO: Full config saved to ./output/config.yaml
[03/19 21:35:34] d2.utils.env INFO: Using a generated random seed 34507443
[03/19 21:35:34] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/19 21:35:34] d2.data.datasets.coco INFO: Loaded 130 images in COCO format from /home/lu/detectron2/potato/COCOformat/train.json
[03/19 21:35:34] d2.data.build INFO: Removed 0 images with no usable annotations. 130 images left.
[03/19 21:35:34] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |
|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| __backgroun.. | 659          |   potato   | 934          |    weed    | 0            |
|               |              |            |              |            |              |
|     total     | 1593         |            |              |            |              |[0m
[03/19 21:35:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.9, 0.9]), ResizeShortestEdge(short_edge_length=(512, 768), max_size=640), RandomFlip()]
[03/19 21:35:34] d2.data.build INFO: Using training sampler TrainingSampler
[03/19 21:35:34] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:35:34] d2.data.common INFO: Serializing 130 elements to byte tensors and concatenating them all ...
[03/19 21:35:34] d2.data.common INFO: Serialized dataset takes 0.61 MiB
[03/19 21:35:34] d2.data.build INFO: Making batched data loader with batch_size=4
[03/19 21:35:34] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[03/19 21:35:34] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:35:34] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:35:34] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/19 21:35:34] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up - Total num: 54
[03/19 21:35:34] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.{bias, weight}[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[03/19 21:35:34] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/19 21:35:34] d2.engine.train_loop INFO: Starting training from iteration 0
[03/19 21:35:39] d2.utils.events INFO:  eta: 0:08:17  iter: 19  total_loss: 5.102  loss_cls: 3.305  loss_box_reg: 0.08211  loss_mask: 0.6915  loss_rpn_cls: 0.6815  loss_rpn_loc: 0.3168    time: 0.2093  last_time: 0.2115  data_time: 0.0114  last_data_time: 0.0034   lr: 3.9962e-05  max_mem: 2119M
[03/19 21:35:43] d2.utils.events INFO:  eta: 0:08:15  iter: 39  total_loss: 2.412  loss_cls: 0.6814  loss_box_reg: 0.08454  loss_mask: 0.6782  loss_rpn_cls: 0.6594  loss_rpn_loc: 0.2776    time: 0.2118  last_time: 0.2285  data_time: 0.0033  last_data_time: 0.0033   lr: 7.9922e-05  max_mem: 2167M
[03/19 21:35:48] d2.utils.events INFO:  eta: 0:08:19  iter: 59  total_loss: 2.11  loss_cls: 0.523  loss_box_reg: 0.09986  loss_mask: 0.6641  loss_rpn_cls: 0.6111  loss_rpn_loc: 0.2563    time: 0.2150  last_time: 0.2278  data_time: 0.0030  last_data_time: 0.0031   lr: 0.00011988  max_mem: 2167M
[03/19 21:35:53] d2.utils.events INFO:  eta: 0:08:23  iter: 79  total_loss: 1.839  loss_cls: 0.309  loss_box_reg: 0.1289  loss_mask: 0.6645  loss_rpn_cls: 0.5189  loss_rpn_loc: 0.2275    time: 0.2200  last_time: 0.2417  data_time: 0.0029  last_data_time: 0.0028   lr: 0.00015984  max_mem: 2232M
[03/19 21:35:57] d2.utils.events INFO:  eta: 0:08:30  iter: 99  total_loss: 1.914  loss_cls: 0.2931  loss_box_reg: 0.205  loss_mask: 0.6556  loss_rpn_cls: 0.4819  loss_rpn_loc: 0.2356    time: 0.2224  last_time: 0.2313  data_time: 0.0031  last_data_time: 0.0027   lr: 0.0001998  max_mem: 2360M
[03/19 21:36:02] d2.utils.events INFO:  eta: 0:08:27  iter: 119  total_loss: 1.678  loss_cls: 0.2552  loss_box_reg: 0.2417  loss_mask: 0.6438  loss_rpn_cls: 0.3678  loss_rpn_loc: 0.1872    time: 0.2233  last_time: 0.2313  data_time: 0.0028  last_data_time: 0.0031   lr: 0.00023976  max_mem: 2438M
[03/19 21:36:06] d2.utils.events INFO:  eta: 0:08:28  iter: 139  total_loss: 1.658  loss_cls: 0.2384  loss_box_reg: 0.2646  loss_mask: 0.6427  loss_rpn_cls: 0.3242  loss_rpn_loc: 0.2225    time: 0.2239  last_time: 0.2260  data_time: 0.0031  last_data_time: 0.0030   lr: 0.00027972  max_mem: 2438M
[03/19 21:36:11] d2.utils.events INFO:  eta: 0:08:26  iter: 159  total_loss: 1.649  loss_cls: 0.2462  loss_box_reg: 0.3221  loss_mask: 0.6257  loss_rpn_cls: 0.2647  loss_rpn_loc: 0.2107    time: 0.2256  last_time: 0.2486  data_time: 0.0032  last_data_time: 0.0032   lr: 0.00031968  max_mem: 2529M
[03/19 21:36:16] d2.utils.events INFO:  eta: 0:08:27  iter: 179  total_loss: 1.761  loss_cls: 0.2908  loss_box_reg: 0.4685  loss_mask: 0.6245  loss_rpn_cls: 0.1859  loss_rpn_loc: 0.1765    time: 0.2286  last_time: 0.2517  data_time: 0.0031  last_data_time: 0.0028   lr: 0.00035964  max_mem: 2730M
[03/19 21:36:21] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000198.pth
[03/19 21:36:22] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:36:22] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |
|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| __backgroun.. | 82           |   potato   | 138          |    weed    | 0            |
|               |              |            |              |            |              |
|     total     | 220          |            |              |            |              |[0m
[03/19 21:36:22] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:36:22] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:36:22] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:36:22] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:36:22] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:36:23] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0003 s/iter. Inference: 0.0336 s/iter. Eval: 0.0318 s/iter. Total: 0.0657 s/iter. ETA=0:00:00
[03/19 21:36:23] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.067458 (0.071164 s / iter per device, on 1 devices)
[03/19 21:36:23] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.034304 s / iter per device, on 1 devices)
[03/19 21:36:23] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:36:23] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:36:23] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:36:23] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:36:23] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:36:23] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:36:23] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:36:23] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 14.352 | 47.142 | 1.998  | 10.840 | 20.911 | 22.513 |
[03/19 21:36:23] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 156, in train
    self.after_step()
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 190, in after_step
    h.after_step()
  File "/home/lu/detectron2/detectron2/engine/hooks.py", line 556, in after_step
    self._do_eval()
  File "/home/lu/detectron2/detectron2/engine/hooks.py", line 529, in _do_eval
    results = self._func()
  File "/home/lu/detectron2/detectron2/engine/defaults.py", line 455, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/home/lu/detectron2/detectron2/engine/defaults.py", line 619, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/home/lu/detectron2/detectron2/evaluation/evaluator.py", line 213, in inference_on_dataset
    results = evaluator.evaluate()
  File "/home/lu/detectron2/detectron2/evaluation/coco_evaluation.py", line 206, in evaluate
    self._eval_predictions(predictions, img_ids=img_ids)
  File "/home/lu/detectron2/detectron2/evaluation/coco_evaluation.py", line 279, in _eval_predictions
    res = self._derive_coco_results(
  File "/home/lu/detectron2/detectron2/evaluation/coco_evaluation.py", line 364, in _derive_coco_results
    assert len(class_names) == precisions.shape[2]
AssertionError
[03/19 21:36:23] d2.engine.hooks INFO: Overall training speed: 197 iterations in 0:00:45 (0.2334 s / it)
[03/19 21:36:23] d2.engine.hooks INFO: Total training time: 0:00:48 (0:00:02 on hooks)
[03/19 21:36:23] d2.utils.events INFO:  eta: 0:08:25  iter: 199  total_loss: 1.788  loss_cls: 0.2801  loss_box_reg: 0.5493  loss_mask: 0.6038  loss_rpn_cls: 0.1523  loss_rpn_loc: 0.1944    time: 0.2322  last_time: 0.2646  data_time: 0.0031  last_data_time: 0.0056   lr: 0.0003996  max_mem: 2744M
[03/19 21:39:37] detectron2 INFO: Rank of current process: 0. World size: 1
[03/19 21:39:38] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
numpy                            1.24.3
detectron2                       0.6 @/home/lu/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Ti (arch=8.6)
Driver version                   545.29.06
CUDA_HOME                        None - invalid!
Pillow                           10.2.0
torchvision                      0.17.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision
torchvision arch flags           /home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[03/19 21:39:38] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[03/19 21:39:38] detectron2 INFO: Contents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[03/19 21:39:38] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_my_val
  TRAIN:
  - coco_my_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 640
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 512
  - 768
  MIN_SIZE_TRAIN_SAMPLING: range
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 2
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.02
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 100
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/19 21:39:38] detectron2 INFO: Full config saved to ./output/config.yaml
[03/19 21:39:38] d2.utils.env INFO: Using a generated random seed 38264480
[03/19 21:39:38] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/19 21:39:38] d2.data.datasets.coco INFO: Loaded 130 images in COCO format from /home/lu/detectron2/potato/COCOformat/train.json
[03/19 21:39:38] d2.data.build INFO: Removed 0 images with no usable annotations. 130 images left.
[03/19 21:39:38] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |
|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| __backgroun.. | 659          |   potato   | 934          |    weed    | 0            |
|               |              |            |              |            |              |
|     total     | 1593         |            |              |            |              |[0m
[03/19 21:39:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.9, 0.9]), ResizeShortestEdge(short_edge_length=(512, 768), max_size=640), RandomFlip()]
[03/19 21:39:38] d2.data.build INFO: Using training sampler TrainingSampler
[03/19 21:39:38] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:39:38] d2.data.common INFO: Serializing 130 elements to byte tensors and concatenating them all ...
[03/19 21:39:38] d2.data.common INFO: Serialized dataset takes 0.61 MiB
[03/19 21:39:38] d2.data.build INFO: Making batched data loader with batch_size=16
[03/19 21:39:38] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:39:38] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:39:38] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/19 21:39:38] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up - Total num: 54
[03/19 21:39:38] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.{bias, weight}[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[03/19 21:39:38] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/19 21:39:38] d2.engine.train_loop INFO: Starting training from iteration 0
[03/19 21:39:39] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/home/lu/detectron2/detectron2/engine/defaults.py", line 496, in run_step
    self._trainer.run_step()
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 310, in run_step
    loss_dict = self.model(data)
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lu/detectron2/detectron2/modeling/meta_arch/rcnn.py", line 167, in forward
    _, detector_losses = self.roi_heads(images, features, proposals, gt_instances)
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lu/detectron2/detectron2/modeling/roi_heads/roi_heads.py", line 743, in forward
    losses.update(self._forward_mask(features, proposals))
  File "/home/lu/detectron2/detectron2/modeling/roi_heads/roi_heads.py", line 846, in _forward_mask
    return self.mask_head(features, instances)
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lu/detectron2/detectron2/modeling/roi_heads/mask_head.py", line 197, in forward
    x = self.layers(x)
  File "/home/lu/detectron2/detectron2/modeling/roi_heads/mask_head.py", line 289, in layers
    x = layer(x)
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 952, in forward
    return F.conv_transpose2d(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacity of 7.55 GiB of which 286.94 MiB is free. Process 11024 has 890.00 MiB memory in use. Including non-PyTorch memory, this process has 5.78 GiB memory in use. Of the allocated memory 5.26 GiB is allocated by PyTorch, and 317.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[03/19 21:39:39] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/19 21:39:39] d2.utils.events INFO:  iter: 0       lr: N/A  max_mem: 5460M
[03/19 21:41:23] detectron2 INFO: Rank of current process: 0. World size: 1
[03/19 21:41:23] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
numpy                            1.24.3
detectron2                       0.6 @/home/lu/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Ti (arch=8.6)
Driver version                   545.29.06
CUDA_HOME                        None - invalid!
Pillow                           10.2.0
torchvision                      0.17.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision
torchvision arch flags           /home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[03/19 21:41:23] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[03/19 21:41:23] detectron2 INFO: Contents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[03/19 21:41:23] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_my_val
  TRAIN:
  - coco_my_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 640
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 512
  - 768
  MIN_SIZE_TRAIN_SAMPLING: range
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 2
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.02
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 100
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/19 21:41:23] detectron2 INFO: Full config saved to ./output/config.yaml
[03/19 21:41:23] d2.utils.env INFO: Using a generated random seed 23616000
[03/19 21:41:23] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/19 21:41:23] d2.data.datasets.coco INFO: Loaded 130 images in COCO format from /home/lu/detectron2/potato/COCOformat/train.json
[03/19 21:41:23] d2.data.build INFO: Removed 0 images with no usable annotations. 130 images left.
[03/19 21:41:23] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |
|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| __backgroun.. | 659          |   potato   | 934          |    weed    | 0            |
|               |              |            |              |            |              |
|     total     | 1593         |            |              |            |              |[0m
[03/19 21:41:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.9, 0.9]), ResizeShortestEdge(short_edge_length=(512, 768), max_size=640), RandomFlip()]
[03/19 21:41:23] d2.data.build INFO: Using training sampler TrainingSampler
[03/19 21:41:23] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:41:23] d2.data.common INFO: Serializing 130 elements to byte tensors and concatenating them all ...
[03/19 21:41:23] d2.data.common INFO: Serialized dataset takes 0.61 MiB
[03/19 21:41:23] d2.data.build INFO: Making batched data loader with batch_size=16
[03/19 21:41:23] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:41:23] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:41:23] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/19 21:41:23] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up - Total num: 54
[03/19 21:41:24] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.{bias, weight}[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[03/19 21:41:24] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/19 21:41:24] d2.engine.train_loop INFO: Starting training from iteration 0
[03/19 21:41:24] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/home/lu/detectron2/detectron2/engine/defaults.py", line 496, in run_step
    self._trainer.run_step()
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 322, in run_step
    losses.backward()
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacity of 7.55 GiB of which 109.50 MiB is free. Process 11024 has 890.00 MiB memory in use. Including non-PyTorch memory, this process has 5.94 GiB memory in use. Of the allocated memory 5.41 GiB is allocated by PyTorch, and 310.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[03/19 21:41:24] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/19 21:41:24] d2.utils.events INFO:  iter: 0       lr: N/A  max_mem: 5665M
[03/19 21:42:04] detectron2 INFO: Rank of current process: 0. World size: 1
[03/19 21:42:04] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
numpy                            1.24.3
detectron2                       0.6 @/home/lu/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Ti (arch=8.6)
Driver version                   545.29.06
CUDA_HOME                        None - invalid!
Pillow                           10.2.0
torchvision                      0.17.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision
torchvision arch flags           /home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[03/19 21:42:04] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[03/19 21:42:04] detectron2 INFO: Contents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[03/19 21:42:04] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_my_val
  TRAIN:
  - coco_my_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 640
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 512
  - 768
  MIN_SIZE_TRAIN_SAMPLING: range
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 2
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.02
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 270000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 100
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/19 21:42:04] detectron2 INFO: Full config saved to ./output/config.yaml
[03/19 21:42:04] d2.utils.env INFO: Using a generated random seed 4469816
[03/19 21:42:04] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/19 21:42:04] d2.data.datasets.coco INFO: Loaded 130 images in COCO format from /home/lu/detectron2/potato/COCOformat/train.json
[03/19 21:42:04] d2.data.build INFO: Removed 0 images with no usable annotations. 130 images left.
[03/19 21:42:04] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |
|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| __backgroun.. | 659          |   potato   | 934          |    weed    | 0            |
|               |              |            |              |            |              |
|     total     | 1593         |            |              |            |              |[0m
[03/19 21:42:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.9, 0.9]), ResizeShortestEdge(short_edge_length=(512, 768), max_size=640), RandomFlip()]
[03/19 21:42:04] d2.data.build INFO: Using training sampler TrainingSampler
[03/19 21:42:04] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:42:04] d2.data.common INFO: Serializing 130 elements to byte tensors and concatenating them all ...
[03/19 21:42:04] d2.data.common INFO: Serialized dataset takes 0.61 MiB
[03/19 21:42:04] d2.data.build INFO: Making batched data loader with batch_size=4
[03/19 21:42:04] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:42:04] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:42:04] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/19 21:42:04] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up - Total num: 54
[03/19 21:42:04] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.{bias, weight}[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[03/19 21:42:04] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/19 21:42:04] d2.engine.train_loop INFO: Starting training from iteration 0
[03/19 21:42:09] d2.utils.events INFO:  eta: 16:32:25  iter: 19  total_loss: 2.756  loss_cls: 1.023  loss_box_reg: 0.08736  loss_mask: 0.6893  loss_rpn_cls: 0.6979  loss_rpn_loc: 0.2902    time: 0.2191  last_time: 0.2270  data_time: 0.0125  last_data_time: 0.0033   lr: 0.00039962  max_mem: 2118M
[03/19 21:42:14] d2.utils.events INFO:  eta: 17:01:32  iter: 39  total_loss: 2.126  loss_cls: 0.3842  loss_box_reg: 0.1145  loss_mask: 0.6643  loss_rpn_cls: 0.6058  loss_rpn_loc: 0.2902    time: 0.2297  last_time: 0.2590  data_time: 0.0031  last_data_time: 0.0032   lr: 0.00079922  max_mem: 2179M
[03/19 21:42:19] d2.utils.events INFO:  eta: 17:36:15  iter: 59  total_loss: 1.855  loss_cls: 0.2809  loss_box_reg: 0.1918  loss_mask: 0.648  loss_rpn_cls: 0.4425  loss_rpn_loc: 0.2504    time: 0.2361  last_time: 0.2410  data_time: 0.0032  last_data_time: 0.0029   lr: 0.0011988  max_mem: 2723M
[03/19 21:42:24] d2.utils.events INFO:  eta: 17:34:58  iter: 79  total_loss: 1.724  loss_cls: 0.2825  loss_box_reg: 0.3144  loss_mask: 0.6225  loss_rpn_cls: 0.2493  loss_rpn_loc: 0.2341    time: 0.2358  last_time: 0.2221  data_time: 0.0030  last_data_time: 0.0026   lr: 0.0015984  max_mem: 2723M
[03/19 21:42:29] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:42:29] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |
|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| __backgroun.. | 82           |   potato   | 138          |    weed    | 0            |
|               |              |            |              |            |              |
|     total     | 220          |            |              |            |              |[0m
[03/19 21:42:29] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:42:29] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:42:29] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:42:29] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:42:29] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:42:30] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0005 s/iter. Inference: 0.0342 s/iter. Eval: 0.0332 s/iter. Total: 0.0679 s/iter. ETA=0:00:00
[03/19 21:42:31] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.079888 (0.071993 s / iter per device, on 1 devices)
[03/19 21:42:31] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.034817 s / iter per device, on 1 devices)
[03/19 21:42:31] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:42:31] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:42:31] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:42:31] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:42:31] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:42:31] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:42:31] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:42:31] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |
|:------:|:------:|:------:|:------:|:------:|:-----:|
| 13.719 | 45.062 | 1.300  | 14.721 | 15.114 | 7.537 |
[03/19 21:42:31] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 156, in train
    self.after_step()
  File "/home/lu/detectron2/detectron2/engine/train_loop.py", line 190, in after_step
    h.after_step()
  File "/home/lu/detectron2/detectron2/engine/hooks.py", line 556, in after_step
    self._do_eval()
  File "/home/lu/detectron2/detectron2/engine/hooks.py", line 529, in _do_eval
    results = self._func()
  File "/home/lu/detectron2/detectron2/engine/defaults.py", line 455, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/home/lu/detectron2/detectron2/engine/defaults.py", line 619, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/home/lu/detectron2/detectron2/evaluation/evaluator.py", line 213, in inference_on_dataset
    results = evaluator.evaluate()
  File "/home/lu/detectron2/detectron2/evaluation/coco_evaluation.py", line 206, in evaluate
    self._eval_predictions(predictions, img_ids=img_ids)
  File "/home/lu/detectron2/detectron2/evaluation/coco_evaluation.py", line 279, in _eval_predictions
    res = self._derive_coco_results(
  File "/home/lu/detectron2/detectron2/evaluation/coco_evaluation.py", line 364, in _derive_coco_results
    assert len(class_names) == precisions.shape[2]
AssertionError
[03/19 21:42:31] d2.engine.hooks INFO: Overall training speed: 97 iterations in 0:00:23 (0.2457 s / it)
[03/19 21:42:31] d2.engine.hooks INFO: Total training time: 0:00:25 (0:00:01 on hooks)
[03/19 21:42:31] d2.utils.events INFO:  eta: 17:51:05  iter: 99  total_loss: 1.815  loss_cls: 0.3596  loss_box_reg: 0.5811  loss_mask: 0.5683  loss_rpn_cls: 0.1484  loss_rpn_loc: 0.1952    time: 0.2432  last_time: 0.3034  data_time: 0.0031  last_data_time: 0.0034   lr: 0.001998  max_mem: 3062M
[03/19 21:46:30] detectron2 INFO: Rank of current process: 0. World size: 1
[03/19 21:46:30] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
numpy                            1.24.3
detectron2                       0.6 @/home/lu/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Ti (arch=8.6)
Driver version                   545.29.06
CUDA_HOME                        None - invalid!
Pillow                           10.2.0
torchvision                      0.17.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision
torchvision arch flags           /home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[03/19 21:46:30] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[03/19 21:46:30] detectron2 INFO: Contents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[03/19 21:46:30] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_my_val
  TRAIN:
  - coco_my_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 640
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 512
  - 768
  MIN_SIZE_TRAIN_SAMPLING: range
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 2
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 99
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 1199
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 7000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 100
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/19 21:46:30] detectron2 INFO: Full config saved to ./output/config.yaml
[03/19 21:46:30] d2.utils.env INFO: Using a generated random seed 30621965
[03/19 21:46:30] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/19 21:46:30] d2.data.datasets.coco INFO: Loaded 130 images in COCO format from /home/lu/detectron2/potato/COCOformat/train.json
[03/19 21:46:30] d2.data.build INFO: Removed 0 images with no usable annotations. 130 images left.
[03/19 21:46:30] d2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|   potato   | 659          |    weed    | 934          |
|            |              |            |              |
|   total    | 1593         |            |              |[0m
[03/19 21:46:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.9, 0.9]), ResizeShortestEdge(short_edge_length=(512, 768), max_size=640), RandomFlip()]
[03/19 21:46:30] d2.data.build INFO: Using training sampler TrainingSampler
[03/19 21:46:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:46:30] d2.data.common INFO: Serializing 130 elements to byte tensors and concatenating them all ...
[03/19 21:46:30] d2.data.common INFO: Serialized dataset takes 0.61 MiB
[03/19 21:46:30] d2.data.build INFO: Making batched data loader with batch_size=4
[03/19 21:46:30] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[03/19 21:46:30] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:46:30] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 21:46:31] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/19 21:46:31] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up - Total num: 54
[03/19 21:46:31] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.{bias, weight}[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[03/19 21:46:31] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/19 21:46:31] d2.engine.train_loop INFO: Starting training from iteration 0
[03/19 21:46:35] d2.utils.events INFO:  eta: 0:04:03  iter: 19  total_loss: 5.457  loss_cls: 3.711  loss_box_reg: 0.06571  loss_mask: 0.6919  loss_rpn_cls: 0.6805  loss_rpn_loc: 0.337    time: 0.2078  last_time: 0.1999  data_time: 0.0097  last_data_time: 0.0029   lr: 3.9962e-05  max_mem: 2117M
[03/19 21:46:39] d2.utils.events INFO:  eta: 0:04:00  iter: 39  total_loss: 2.22  loss_cls: 0.4477  loss_box_reg: 0.05662  loss_mask: 0.6817  loss_rpn_cls: 0.6593  loss_rpn_loc: 0.3179    time: 0.2073  last_time: 0.2056  data_time: 0.0030  last_data_time: 0.0028   lr: 7.9922e-05  max_mem: 2117M
[03/19 21:46:44] d2.utils.events INFO:  eta: 0:03:58  iter: 59  total_loss: 2.163  loss_cls: 0.5489  loss_box_reg: 0.08655  loss_mask: 0.6663  loss_rpn_cls: 0.6121  loss_rpn_loc: 0.2555    time: 0.2094  last_time: 0.2101  data_time: 0.0032  last_data_time: 0.0031   lr: 0.00011988  max_mem: 2202M
[03/19 21:46:48] d2.utils.events INFO:  eta: 0:03:57  iter: 79  total_loss: 1.914  loss_cls: 0.3586  loss_box_reg: 0.1149  loss_mask: 0.6658  loss_rpn_cls: 0.5536  loss_rpn_loc: 0.2262    time: 0.2147  last_time: 0.2422  data_time: 0.0031  last_data_time: 0.0031   lr: 0.00015984  max_mem: 2220M
[03/19 21:46:52] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000098.pth
[03/19 21:46:53] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:46:53] d2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|   potato   | 82           |    weed    | 138          |
|            |              |            |              |
|   total    | 220          |            |              |[0m
[03/19 21:46:53] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:46:53] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:46:53] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:46:53] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:46:53] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:46:54] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0296 s/iter. Eval: 0.0142 s/iter. Total: 0.0443 s/iter. ETA=0:00:00
[03/19 21:46:54] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.808347 (0.053890 s / iter per device, on 1 devices)
[03/19 21:46:54] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.030849 s / iter per device, on 1 devices)
[03/19 21:46:54] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:46:54] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:46:54] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:46:54] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:46:54] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 21:46:54] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:46:54] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:46:54] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.315 | 1.738  | 0.005  | 0.318 | 0.475 | 0.322 |
[03/19 21:46:54] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| potato     | 0.032 | weed       | 0.599 |
[03/19 21:46:54] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 21:46:54] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:46:54] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:46:54] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:46:54] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.230 | 1.486  | 0.000  | 0.228 | 0.588 | 0.965 |
[03/19 21:46:54] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| potato     | 0.037 | weed       | 0.424 |
[03/19 21:46:54] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 21:46:54] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 21:46:54] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:46:54] d2.evaluation.testing INFO: copypaste: 0.3154,1.7376,0.0052,0.3181,0.4752,0.3218
[03/19 21:46:54] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 21:46:54] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:46:54] d2.evaluation.testing INFO: copypaste: 0.2304,1.4862,0.0000,0.2283,0.5878,0.9653
[03/19 21:46:54] d2.utils.events INFO:  eta: 0:03:55  iter: 99  total_loss: 1.932  loss_cls: 0.299  loss_box_reg: 0.1491  loss_mask: 0.6578  loss_rpn_cls: 0.5305  loss_rpn_loc: 0.274    time: 0.2162  last_time: 0.2278  data_time: 0.0030  last_data_time: 0.0026   lr: 0.0001998  max_mem: 2220M
[03/19 21:46:58] d2.utils.events INFO:  eta: 0:03:53  iter: 119  total_loss: 1.797  loss_cls: 0.2444  loss_box_reg: 0.1682  loss_mask: 0.6477  loss_rpn_cls: 0.4813  loss_rpn_loc: 0.2065    time: 0.2167  last_time: 0.2318  data_time: 0.0032  last_data_time: 0.0033   lr: 0.00023976  max_mem: 2291M
[03/19 21:47:03] d2.utils.events INFO:  eta: 0:03:49  iter: 139  total_loss: 1.649  loss_cls: 0.224  loss_box_reg: 0.1921  loss_mask: 0.6417  loss_rpn_cls: 0.3791  loss_rpn_loc: 0.193    time: 0.2169  last_time: 0.2215  data_time: 0.0032  last_data_time: 0.0034   lr: 0.00027972  max_mem: 2291M
[03/19 21:47:07] d2.utils.events INFO:  eta: 0:03:45  iter: 159  total_loss: 1.61  loss_cls: 0.2668  loss_box_reg: 0.2349  loss_mask: 0.6307  loss_rpn_cls: 0.3104  loss_rpn_loc: 0.2243    time: 0.2180  last_time: 0.2265  data_time: 0.0032  last_data_time: 0.0032   lr: 0.00031968  max_mem: 2531M
[03/19 21:47:12] d2.utils.events INFO:  eta: 0:03:42  iter: 179  total_loss: 1.677  loss_cls: 0.2797  loss_box_reg: 0.3117  loss_mask: 0.6364  loss_rpn_cls: 0.2384  loss_rpn_loc: 0.201    time: 0.2196  last_time: 0.2237  data_time: 0.0033  last_data_time: 0.0033   lr: 0.00035964  max_mem: 2591M
[03/19 21:47:16] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000197.pth
[03/19 21:47:17] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:47:17] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:47:17] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:47:17] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:47:17] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:47:17] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:47:18] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0359 s/iter. Eval: 0.0396 s/iter. Total: 0.0758 s/iter. ETA=0:00:00
[03/19 21:47:19] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.137676 (0.075845 s / iter per device, on 1 devices)
[03/19 21:47:19] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.035388 s / iter per device, on 1 devices)
[03/19 21:47:19] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:47:19] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:47:19] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:47:19] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:47:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:47:19] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:47:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:47:19] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl  |
|:------:|:------:|:------:|:------:|:-----:|:-----:|
| 10.001 | 38.308 | 2.100  | 10.442 | 8.776 | 4.991 |
[03/19 21:47:19] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP    |
|:-----------|:-------|:-----------|:------|
| potato     | 13.348 | weed       | 6.654 |
[03/19 21:47:19] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 21:47:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:47:19] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:47:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:47:19] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 3.420 | 18.952 | 0.001  | 4.821 | 2.640 | 3.395 |
[03/19 21:47:19] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| potato     | 4.840 | weed       | 2.001 |
[03/19 21:47:19] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 21:47:19] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 21:47:19] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:47:19] d2.evaluation.testing INFO: copypaste: 10.0009,38.3085,2.0995,10.4415,8.7760,4.9910
[03/19 21:47:19] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 21:47:19] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:47:19] d2.evaluation.testing INFO: copypaste: 3.4202,18.9515,0.0005,4.8214,2.6399,3.3952
[03/19 21:47:19] d2.utils.events INFO:  eta: 0:03:40  iter: 199  total_loss: 1.616  loss_cls: 0.2749  loss_box_reg: 0.3636  loss_mask: 0.6196  loss_rpn_cls: 0.1641  loss_rpn_loc: 0.169    time: 0.2221  last_time: 0.2405  data_time: 0.0032  last_data_time: 0.0030   lr: 0.0003996  max_mem: 2906M
[03/19 21:47:24] d2.utils.events INFO:  eta: 0:03:37  iter: 219  total_loss: 1.883  loss_cls: 0.3364  loss_box_reg: 0.5621  loss_mask: 0.6104  loss_rpn_cls: 0.1457  loss_rpn_loc: 0.2037    time: 0.2259  last_time: 0.2605  data_time: 0.0034  last_data_time: 0.0032   lr: 0.00043956  max_mem: 2906M
[03/19 21:47:30] d2.utils.events INFO:  eta: 0:03:34  iter: 239  total_loss: 1.843  loss_cls: 0.3082  loss_box_reg: 0.6137  loss_mask: 0.5778  loss_rpn_cls: 0.1464  loss_rpn_loc: 0.1905    time: 0.2302  last_time: 0.2922  data_time: 0.0033  last_data_time: 0.0032   lr: 0.00047952  max_mem: 3072M
[03/19 21:47:35] d2.utils.events INFO:  eta: 0:03:32  iter: 259  total_loss: 1.755  loss_cls: 0.3278  loss_box_reg: 0.6477  loss_mask: 0.5608  loss_rpn_cls: 0.106  loss_rpn_loc: 0.172    time: 0.2345  last_time: 0.2722  data_time: 0.0032  last_data_time: 0.0031   lr: 0.00051948  max_mem: 3132M
[03/19 21:47:41] d2.utils.events INFO:  eta: 0:03:30  iter: 279  total_loss: 1.698  loss_cls: 0.3057  loss_box_reg: 0.5987  loss_mask: 0.4969  loss_rpn_cls: 0.09793  loss_rpn_loc: 0.1984    time: 0.2383  last_time: 0.2795  data_time: 0.0032  last_data_time: 0.0029   lr: 0.00055944  max_mem: 3226M
[03/19 21:47:46] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000296.pth
[03/19 21:47:47] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:47:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:47:47] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:47:47] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:47:47] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:47:47] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:47:48] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0334 s/iter. Eval: 0.0297 s/iter. Total: 0.0635 s/iter. ETA=0:00:00
[03/19 21:47:49] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.029966 (0.068664 s / iter per device, on 1 devices)
[03/19 21:47:49] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.034068 s / iter per device, on 1 devices)
[03/19 21:47:49] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:47:49] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:47:49] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:47:49] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:47:49] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:47:49] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:47:49] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:47:49] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 31.864 | 73.890 | 22.954 | 24.998 | 29.813 | 43.619 |
[03/19 21:47:49] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 47.059 | weed       | 16.669 |
[03/19 21:47:49] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 21:47:49] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:47:49] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:47:49] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:47:49] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 30.978 | 74.337 | 22.223 | 20.467 | 37.491 | 50.684 |
[03/19 21:47:49] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 46.911 | weed       | 15.045 |
[03/19 21:47:49] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 21:47:49] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 21:47:49] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:47:49] d2.evaluation.testing INFO: copypaste: 31.8640,73.8898,22.9537,24.9981,29.8132,43.6192
[03/19 21:47:49] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 21:47:49] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:47:49] d2.evaluation.testing INFO: copypaste: 30.9782,74.3372,22.2227,20.4671,37.4906,50.6836
[03/19 21:47:49] d2.utils.events INFO:  eta: 0:03:27  iter: 299  total_loss: 1.768  loss_cls: 0.3674  loss_box_reg: 0.633  loss_mask: 0.4696  loss_rpn_cls: 0.09968  loss_rpn_loc: 0.1956    time: 0.2420  last_time: 0.2954  data_time: 0.0035  last_data_time: 0.0044   lr: 0.0005994  max_mem: 3226M
[03/19 21:47:55] d2.utils.events INFO:  eta: 0:03:23  iter: 319  total_loss: 1.606  loss_cls: 0.3335  loss_box_reg: 0.5882  loss_mask: 0.3704  loss_rpn_cls: 0.08199  loss_rpn_loc: 0.1633    time: 0.2456  last_time: 0.2995  data_time: 0.0032  last_data_time: 0.0030   lr: 0.00063936  max_mem: 3226M
[03/19 21:48:01] d2.utils.events INFO:  eta: 0:03:22  iter: 339  total_loss: 1.5  loss_cls: 0.3354  loss_box_reg: 0.5868  loss_mask: 0.3394  loss_rpn_cls: 0.08659  loss_rpn_loc: 0.1259    time: 0.2488  last_time: 0.2887  data_time: 0.0028  last_data_time: 0.0033   lr: 0.00067932  max_mem: 3226M
[03/19 21:48:07] d2.utils.events INFO:  eta: 0:03:22  iter: 359  total_loss: 1.462  loss_cls: 0.3089  loss_box_reg: 0.5669  loss_mask: 0.3224  loss_rpn_cls: 0.07767  loss_rpn_loc: 0.1539    time: 0.2516  last_time: 0.3017  data_time: 0.0031  last_data_time: 0.0029   lr: 0.00071928  max_mem: 3226M
[03/19 21:48:13] d2.utils.events INFO:  eta: 0:03:21  iter: 379  total_loss: 1.344  loss_cls: 0.3041  loss_box_reg: 0.5294  loss_mask: 0.2928  loss_rpn_cls: 0.07419  loss_rpn_loc: 0.131    time: 0.2540  last_time: 0.2978  data_time: 0.0031  last_data_time: 0.0034   lr: 0.00075924  max_mem: 3226M
[03/19 21:48:18] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000395.pth
[03/19 21:48:19] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:48:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:48:19] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:48:19] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:48:19] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:48:19] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:48:20] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0291 s/iter. Eval: 0.0094 s/iter. Total: 0.0389 s/iter. ETA=0:00:00
[03/19 21:48:20] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.643280 (0.042885 s / iter per device, on 1 devices)
[03/19 21:48:20] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.029801 s / iter per device, on 1 devices)
[03/19 21:48:20] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:48:20] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:48:20] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:48:20] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:48:20] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 21:48:20] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:48:20] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:48:20] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.860 | 86.215 | 32.447 | 40.324 | 42.866 | 55.587 |
[03/19 21:48:20] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 54.698 | weed       | 31.023 |
[03/19 21:48:20] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 21:48:20] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:48:20] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:48:20] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:48:20] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.802 | 85.276 | 51.282 | 41.203 | 53.830 | 60.594 |
[03/19 21:48:20] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 62.633 | weed       | 30.972 |
[03/19 21:48:20] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 21:48:20] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 21:48:20] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:48:20] d2.evaluation.testing INFO: copypaste: 42.8604,86.2147,32.4470,40.3240,42.8664,55.5870
[03/19 21:48:20] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 21:48:20] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:48:20] d2.evaluation.testing INFO: copypaste: 46.8024,85.2756,51.2818,41.2034,53.8302,60.5941
[03/19 21:48:20] d2.utils.events INFO:  eta: 0:03:23  iter: 399  total_loss: 1.41  loss_cls: 0.3101  loss_box_reg: 0.5562  loss_mask: 0.2892  loss_rpn_cls: 0.08001  loss_rpn_loc: 0.1419    time: 0.2566  last_time: 0.3160  data_time: 0.0033  last_data_time: 0.0035   lr: 0.0007992  max_mem: 3226M
[03/19 21:48:26] d2.utils.events INFO:  eta: 0:03:24  iter: 419  total_loss: 1.308  loss_cls: 0.3185  loss_box_reg: 0.5332  loss_mask: 0.2651  loss_rpn_cls: 0.06636  loss_rpn_loc: 0.1486    time: 0.2587  last_time: 0.2865  data_time: 0.0032  last_data_time: 0.0031   lr: 0.00083916  max_mem: 3226M
[03/19 21:48:32] d2.utils.events INFO:  eta: 0:03:22  iter: 439  total_loss: 1.301  loss_cls: 0.3043  loss_box_reg: 0.5193  loss_mask: 0.256  loss_rpn_cls: 0.07112  loss_rpn_loc: 0.1414    time: 0.2608  last_time: 0.3112  data_time: 0.0033  last_data_time: 0.0033   lr: 0.00087912  max_mem: 3227M
[03/19 21:48:38] d2.utils.events INFO:  eta: 0:03:21  iter: 459  total_loss: 1.369  loss_cls: 0.2987  loss_box_reg: 0.5225  loss_mask: 0.2573  loss_rpn_cls: 0.09399  loss_rpn_loc: 0.1804    time: 0.2627  last_time: 0.2953  data_time: 0.0033  last_data_time: 0.0034   lr: 0.00091908  max_mem: 3228M
[03/19 21:48:45] d2.utils.events INFO:  eta: 0:03:17  iter: 479  total_loss: 1.241  loss_cls: 0.3101  loss_box_reg: 0.4962  loss_mask: 0.252  loss_rpn_cls: 0.06825  loss_rpn_loc: 0.1372    time: 0.2652  last_time: 0.3143  data_time: 0.0032  last_data_time: 0.0032   lr: 0.00095904  max_mem: 3228M
[03/19 21:48:49] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000494.pth
[03/19 21:48:51] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:48:51] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:48:51] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:48:51] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:48:51] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:48:51] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:48:52] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0299 s/iter. Eval: 0.0103 s/iter. Total: 0.0406 s/iter. ETA=0:00:00
[03/19 21:48:52] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.659853 (0.043990 s / iter per device, on 1 devices)
[03/19 21:48:52] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.029718 s / iter per device, on 1 devices)
[03/19 21:48:52] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:48:52] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:48:52] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:48:52] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:48:52] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 21:48:52] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:48:52] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:48:52] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.954 | 87.880 | 52.647 | 46.653 | 47.592 | 56.845 |
[03/19 21:48:52] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 64.948 | weed       | 32.960 |
[03/19 21:48:52] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 21:48:52] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:48:52] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:48:52] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:48:52] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.908 | 88.804 | 57.740 | 49.112 | 57.558 | 60.820 |
[03/19 21:48:52] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 69.577 | weed       | 34.239 |
[03/19 21:48:52] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 21:48:52] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 21:48:52] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:48:52] d2.evaluation.testing INFO: copypaste: 48.9542,87.8800,52.6466,46.6531,47.5921,56.8449
[03/19 21:48:52] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 21:48:52] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:48:52] d2.evaluation.testing INFO: copypaste: 51.9081,88.8038,57.7396,49.1122,57.5580,60.8196
[03/19 21:48:52] d2.utils.events INFO:  eta: 0:03:13  iter: 499  total_loss: 1.222  loss_cls: 0.2766  loss_box_reg: 0.4836  loss_mask: 0.2384  loss_rpn_cls: 0.06783  loss_rpn_loc: 0.1466    time: 0.2669  last_time: 0.3057  data_time: 0.0033  last_data_time: 0.0033   lr: 0.000999  max_mem: 3228M
[03/19 21:48:58] d2.utils.events INFO:  eta: 0:03:10  iter: 519  total_loss: 1.253  loss_cls: 0.2931  loss_box_reg: 0.4953  loss_mask: 0.2386  loss_rpn_cls: 0.06435  loss_rpn_loc: 0.1461    time: 0.2686  last_time: 0.3222  data_time: 0.0034  last_data_time: 0.0046   lr: 0.001039  max_mem: 3228M
[03/19 21:49:04] d2.utils.events INFO:  eta: 0:03:07  iter: 539  total_loss: 1.232  loss_cls: 0.2811  loss_box_reg: 0.5007  loss_mask: 0.2414  loss_rpn_cls: 0.07108  loss_rpn_loc: 0.1422    time: 0.2700  last_time: 0.2895  data_time: 0.0033  last_data_time: 0.0034   lr: 0.0010789  max_mem: 3228M
[03/19 21:49:11] d2.utils.events INFO:  eta: 0:03:02  iter: 559  total_loss: 1.175  loss_cls: 0.2705  loss_box_reg: 0.465  loss_mask: 0.2243  loss_rpn_cls: 0.05061  loss_rpn_loc: 0.1233    time: 0.2713  last_time: 0.3136  data_time: 0.0034  last_data_time: 0.0031   lr: 0.0011189  max_mem: 3228M
[03/19 21:49:17] d2.utils.events INFO:  eta: 0:02:58  iter: 579  total_loss: 1.21  loss_cls: 0.285  loss_box_reg: 0.4932  loss_mask: 0.2366  loss_rpn_cls: 0.0593  loss_rpn_loc: 0.1288    time: 0.2727  last_time: 0.3139  data_time: 0.0035  last_data_time: 0.0034   lr: 0.0011588  max_mem: 3228M
[03/19 21:49:21] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000593.pth
[03/19 21:49:23] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:49:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:49:23] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:49:23] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:49:23] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:49:23] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:49:24] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0281 s/iter. Eval: 0.0095 s/iter. Total: 0.0380 s/iter. ETA=0:00:00
[03/19 21:49:24] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.620417 (0.041361 s / iter per device, on 1 devices)
[03/19 21:49:24] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.028638 s / iter per device, on 1 devices)
[03/19 21:49:24] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:49:24] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:49:24] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:49:24] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:49:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 21:49:24] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:49:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:49:24] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 54.323 | 90.467 | 56.122 | 50.691 | 53.499 | 71.098 |
[03/19 21:49:24] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 72.721 | weed       | 35.926 |
[03/19 21:49:24] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 21:49:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:49:24] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:49:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:49:24] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 54.847 | 91.583 | 62.456 | 50.100 | 59.300 | 64.620 |
[03/19 21:49:24] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 72.132 | weed       | 37.563 |
[03/19 21:49:24] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 21:49:24] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 21:49:24] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:49:24] d2.evaluation.testing INFO: copypaste: 54.3233,90.4671,56.1216,50.6910,53.4992,71.0976
[03/19 21:49:24] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 21:49:24] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:49:24] d2.evaluation.testing INFO: copypaste: 54.8474,91.5828,62.4555,50.1002,59.2999,64.6205
[03/19 21:49:24] d2.utils.events INFO:  eta: 0:02:53  iter: 599  total_loss: 1.165  loss_cls: 0.2673  loss_box_reg: 0.4511  loss_mask: 0.2197  loss_rpn_cls: 0.0694  loss_rpn_loc: 0.1443    time: 0.2737  last_time: 0.2817  data_time: 0.0034  last_data_time: 0.0038   lr: 0.0011988  max_mem: 3228M
[03/19 21:49:30] d2.utils.events INFO:  eta: 0:02:48  iter: 619  total_loss: 1.082  loss_cls: 0.2406  loss_box_reg: 0.4507  loss_mask: 0.2175  loss_rpn_cls: 0.06529  loss_rpn_loc: 0.1113    time: 0.2746  last_time: 0.2835  data_time: 0.0035  last_data_time: 0.0033   lr: 0.0012388  max_mem: 3228M
[03/19 21:49:36] d2.utils.events INFO:  eta: 0:02:43  iter: 639  total_loss: 1.121  loss_cls: 0.2611  loss_box_reg: 0.4734  loss_mask: 0.2269  loss_rpn_cls: 0.05738  loss_rpn_loc: 0.1117    time: 0.2755  last_time: 0.2883  data_time: 0.0035  last_data_time: 0.0036   lr: 0.0012787  max_mem: 3228M
[03/19 21:49:42] d2.utils.events INFO:  eta: 0:02:38  iter: 659  total_loss: 1.111  loss_cls: 0.2473  loss_box_reg: 0.4436  loss_mask: 0.2258  loss_rpn_cls: 0.0587  loss_rpn_loc: 0.1285    time: 0.2762  last_time: 0.3111  data_time: 0.0032  last_data_time: 0.0032   lr: 0.0013187  max_mem: 3228M
[03/19 21:49:48] d2.utils.events INFO:  eta: 0:02:32  iter: 679  total_loss: 1.119  loss_cls: 0.243  loss_box_reg: 0.4315  loss_mask: 0.2136  loss_rpn_cls: 0.05725  loss_rpn_loc: 0.1352    time: 0.2772  last_time: 0.2920  data_time: 0.0031  last_data_time: 0.0030   lr: 0.0013586  max_mem: 3228M
[03/19 21:49:52] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000692.pth
[03/19 21:49:55] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:49:55] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:49:55] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:49:55] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:49:55] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:49:55] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:49:55] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0276 s/iter. Eval: 0.0083 s/iter. Total: 0.0363 s/iter. ETA=0:00:00
[03/19 21:49:56] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.607828 (0.040522 s / iter per device, on 1 devices)
[03/19 21:49:56] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.028442 s / iter per device, on 1 devices)
[03/19 21:49:56] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:49:56] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:49:56] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:49:56] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:49:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 21:49:56] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:49:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:49:56] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.475 | 89.059 | 61.865 | 47.899 | 51.524 | 66.202 |
[03/19 21:49:56] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 69.997 | weed       | 36.953 |
[03/19 21:49:56] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 21:49:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:49:56] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:49:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:49:56] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 55.186 | 90.400 | 62.149 | 47.781 | 59.428 | 67.341 |
[03/19 21:49:56] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 73.466 | weed       | 36.906 |
[03/19 21:49:56] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 21:49:56] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 21:49:56] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:49:56] d2.evaluation.testing INFO: copypaste: 53.4751,89.0588,61.8645,47.8993,51.5242,66.2023
[03/19 21:49:56] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 21:49:56] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:49:56] d2.evaluation.testing INFO: copypaste: 55.1863,90.3996,62.1487,47.7814,59.4281,67.3409
[03/19 21:49:56] d2.utils.events INFO:  eta: 0:02:27  iter: 699  total_loss: 1.011  loss_cls: 0.259  loss_box_reg: 0.4255  loss_mask: 0.2082  loss_rpn_cls: 0.04807  loss_rpn_loc: 0.09548    time: 0.2779  last_time: 0.2928  data_time: 0.0032  last_data_time: 0.0036   lr: 0.0013986  max_mem: 3228M
[03/19 21:50:02] d2.utils.events INFO:  eta: 0:02:21  iter: 719  total_loss: 1.102  loss_cls: 0.2584  loss_box_reg: 0.4273  loss_mask: 0.2147  loss_rpn_cls: 0.04965  loss_rpn_loc: 0.1288    time: 0.2787  last_time: 0.3030  data_time: 0.0032  last_data_time: 0.0030   lr: 0.0014386  max_mem: 3228M
[03/19 21:50:08] d2.utils.events INFO:  eta: 0:02:15  iter: 739  total_loss: 1.048  loss_cls: 0.2397  loss_box_reg: 0.3985  loss_mask: 0.2095  loss_rpn_cls: 0.06039  loss_rpn_loc: 0.1209    time: 0.2794  last_time: 0.3150  data_time: 0.0033  last_data_time: 0.0031   lr: 0.0014785  max_mem: 3228M
[03/19 21:50:14] d2.utils.events INFO:  eta: 0:02:10  iter: 759  total_loss: 1.075  loss_cls: 0.2589  loss_box_reg: 0.4272  loss_mask: 0.2131  loss_rpn_cls: 0.05275  loss_rpn_loc: 0.1219    time: 0.2801  last_time: 0.3122  data_time: 0.0031  last_data_time: 0.0030   lr: 0.0015185  max_mem: 3228M
[03/19 21:50:20] d2.utils.events INFO:  eta: 0:02:04  iter: 779  total_loss: 1.042  loss_cls: 0.2442  loss_box_reg: 0.4176  loss_mask: 0.2075  loss_rpn_cls: 0.05798  loss_rpn_loc: 0.1265    time: 0.2807  last_time: 0.2906  data_time: 0.0030  last_data_time: 0.0030   lr: 0.0015584  max_mem: 3228M
[03/19 21:50:24] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000791.pth
[03/19 21:50:26] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:50:26] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:50:26] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:50:26] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:50:26] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:50:26] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:50:27] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0265 s/iter. Eval: 0.0069 s/iter. Total: 0.0338 s/iter. ETA=0:00:00
[03/19 21:50:27] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.564721 (0.037648 s / iter per device, on 1 devices)
[03/19 21:50:27] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.027412 s / iter per device, on 1 devices)
[03/19 21:50:27] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:50:27] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:50:27] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:50:27] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:50:27] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 21:50:27] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:50:27] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:50:27] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.601 | 90.128 | 57.612 | 46.686 | 56.748 | 73.792 |
[03/19 21:50:27] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 70.410 | weed       | 34.791 |
[03/19 21:50:27] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 21:50:27] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:50:27] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:50:27] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:50:27] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 57.443 | 89.863 | 64.779 | 50.475 | 65.087 | 67.341 |
[03/19 21:50:27] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 74.849 | weed       | 40.036 |
[03/19 21:50:27] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 21:50:27] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 21:50:27] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:50:27] d2.evaluation.testing INFO: copypaste: 52.6006,90.1275,57.6116,46.6862,56.7481,73.7921
[03/19 21:50:27] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 21:50:27] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:50:27] d2.evaluation.testing INFO: copypaste: 57.4427,89.8628,64.7792,50.4753,65.0866,67.3409
[03/19 21:50:27] d2.utils.events INFO:  eta: 0:01:58  iter: 799  total_loss: 1.024  loss_cls: 0.2312  loss_box_reg: 0.4055  loss_mask: 0.206  loss_rpn_cls: 0.05784  loss_rpn_loc: 0.1322    time: 0.2813  last_time: 0.2942  data_time: 0.0030  last_data_time: 0.0032   lr: 0.0015984  max_mem: 3228M
[03/19 21:50:33] d2.utils.events INFO:  eta: 0:01:52  iter: 819  total_loss: 0.988  loss_cls: 0.2314  loss_box_reg: 0.3787  loss_mask: 0.2005  loss_rpn_cls: 0.03788  loss_rpn_loc: 0.0942    time: 0.2819  last_time: 0.2984  data_time: 0.0031  last_data_time: 0.0031   lr: 0.0016384  max_mem: 3228M
[03/19 21:50:39] d2.utils.events INFO:  eta: 0:01:47  iter: 839  total_loss: 1.046  loss_cls: 0.2353  loss_box_reg: 0.4128  loss_mask: 0.213  loss_rpn_cls: 0.06213  loss_rpn_loc: 0.1277    time: 0.2825  last_time: 0.3109  data_time: 0.0031  last_data_time: 0.0034   lr: 0.0016783  max_mem: 3228M
[03/19 21:50:46] d2.utils.events INFO:  eta: 0:01:41  iter: 859  total_loss: 1.03  loss_cls: 0.2456  loss_box_reg: 0.431  loss_mask: 0.1971  loss_rpn_cls: 0.05492  loss_rpn_loc: 0.1165    time: 0.2830  last_time: 0.3155  data_time: 0.0032  last_data_time: 0.0031   lr: 0.0017183  max_mem: 3228M
[03/19 21:50:52] d2.utils.events INFO:  eta: 0:01:35  iter: 879  total_loss: 0.967  loss_cls: 0.2113  loss_box_reg: 0.3905  loss_mask: 0.2048  loss_rpn_cls: 0.04988  loss_rpn_loc: 0.09934    time: 0.2835  last_time: 0.2926  data_time: 0.0032  last_data_time: 0.0037   lr: 0.0017582  max_mem: 3228M
[03/19 21:50:55] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000890.pth
[03/19 21:50:59] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:50:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:50:59] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:50:59] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:50:59] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:50:59] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:50:59] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0263 s/iter. Eval: 0.0060 s/iter. Total: 0.0326 s/iter. ETA=0:00:00
[03/19 21:50:59] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.544050 (0.036270 s / iter per device, on 1 devices)
[03/19 21:50:59] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.027063 s / iter per device, on 1 devices)
[03/19 21:50:59] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:50:59] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:50:59] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:50:59] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:50:59] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 21:50:59] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:50:59] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:50:59] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 58.554 | 91.702 | 66.964 | 52.052 | 62.623 | 76.951 |
[03/19 21:50:59] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 77.351 | weed       | 39.757 |
[03/19 21:50:59] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 21:51:00] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:51:00] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:51:00] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:51:00] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 59.863 | 92.724 | 68.542 | 53.959 | 65.337 | 68.069 |
[03/19 21:51:00] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 75.572 | weed       | 44.154 |
[03/19 21:51:00] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 21:51:00] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 21:51:00] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:51:00] d2.evaluation.testing INFO: copypaste: 58.5542,91.7025,66.9637,52.0519,62.6228,76.9513
[03/19 21:51:00] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 21:51:00] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:51:00] d2.evaluation.testing INFO: copypaste: 59.8628,92.7239,68.5415,53.9587,65.3368,68.0693
[03/19 21:51:00] d2.utils.events INFO:  eta: 0:01:29  iter: 899  total_loss: 0.9839  loss_cls: 0.236  loss_box_reg: 0.4051  loss_mask: 0.1911  loss_rpn_cls: 0.05583  loss_rpn_loc: 0.1164    time: 0.2847  last_time: 0.3155  data_time: 0.0032  last_data_time: 0.0035   lr: 0.0017982  max_mem: 3228M
[03/19 21:51:06] d2.utils.events INFO:  eta: 0:01:23  iter: 919  total_loss: 1.013  loss_cls: 0.2302  loss_box_reg: 0.3955  loss_mask: 0.1954  loss_rpn_cls: 0.0497  loss_rpn_loc: 0.1079    time: 0.2852  last_time: 0.3127  data_time: 0.0033  last_data_time: 0.0033   lr: 0.0018382  max_mem: 3228M
[03/19 21:51:13] d2.utils.events INFO:  eta: 0:01:17  iter: 939  total_loss: 1.002  loss_cls: 0.2159  loss_box_reg: 0.3813  loss_mask: 0.2081  loss_rpn_cls: 0.05434  loss_rpn_loc: 0.1122    time: 0.2864  last_time: 0.3131  data_time: 0.0031  last_data_time: 0.0030   lr: 0.0018781  max_mem: 3228M
[03/19 21:51:20] d2.utils.events INFO:  eta: 0:01:11  iter: 959  total_loss: 1.02  loss_cls: 0.2311  loss_box_reg: 0.4073  loss_mask: 0.1972  loss_rpn_cls: 0.04814  loss_rpn_loc: 0.1229    time: 0.2877  last_time: 0.4664  data_time: 0.0032  last_data_time: 0.0036   lr: 0.0019181  max_mem: 3228M
[03/19 21:51:26] d2.utils.events INFO:  eta: 0:01:05  iter: 979  total_loss: 0.9561  loss_cls: 0.2265  loss_box_reg: 0.4042  loss_mask: 0.1901  loss_rpn_cls: 0.04825  loss_rpn_loc: 0.09813    time: 0.2887  last_time: 0.2975  data_time: 0.0032  last_data_time: 0.0036   lr: 0.001958  max_mem: 3228M
[03/19 21:51:29] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000989.pth
[03/19 21:51:33] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:51:33] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:51:33] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:51:33] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:51:33] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:51:33] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:51:33] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0265 s/iter. Eval: 0.0065 s/iter. Total: 0.0335 s/iter. ETA=0:00:00
[03/19 21:51:34] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.567899 (0.037860 s / iter per device, on 1 devices)
[03/19 21:51:34] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.027662 s / iter per device, on 1 devices)
[03/19 21:51:34] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:51:34] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:51:34] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:51:34] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:51:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 21:51:34] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:51:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:51:34] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 54.915 | 92.227 | 63.214 | 48.891 | 55.937 | 67.480 |
[03/19 21:51:34] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 67.401 | weed       | 42.430 |
[03/19 21:51:34] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 21:51:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:51:34] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:51:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:51:34] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 59.070 | 91.249 | 67.914 | 55.006 | 63.957 | 67.426 |
[03/19 21:51:34] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 73.839 | weed       | 44.302 |
[03/19 21:51:34] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 21:51:34] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 21:51:34] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:51:34] d2.evaluation.testing INFO: copypaste: 54.9154,92.2273,63.2141,48.8910,55.9372,67.4800
[03/19 21:51:34] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 21:51:34] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:51:34] d2.evaluation.testing INFO: copypaste: 59.0705,91.2487,67.9139,55.0058,63.9571,67.4257
[03/19 21:51:34] d2.utils.events INFO:  eta: 0:00:59  iter: 999  total_loss: 0.9277  loss_cls: 0.2032  loss_box_reg: 0.3895  loss_mask: 0.1863  loss_rpn_cls: 0.05294  loss_rpn_loc: 0.09842    time: 0.2891  last_time: 0.3065  data_time: 0.0035  last_data_time: 0.0034   lr: 0.001998  max_mem: 3228M
[03/19 21:51:40] d2.utils.events INFO:  eta: 0:00:53  iter: 1019  total_loss: 0.9539  loss_cls: 0.2158  loss_box_reg: 0.3856  loss_mask: 0.1907  loss_rpn_cls: 0.04991  loss_rpn_loc: 0.1122    time: 0.2894  last_time: 0.2988  data_time: 0.0031  last_data_time: 0.0029   lr: 0.002  max_mem: 3228M
[03/19 21:51:46] d2.utils.events INFO:  eta: 0:00:47  iter: 1039  total_loss: 0.9623  loss_cls: 0.2372  loss_box_reg: 0.3937  loss_mask: 0.1892  loss_rpn_cls: 0.04032  loss_rpn_loc: 0.1136    time: 0.2897  last_time: 0.2648  data_time: 0.0034  last_data_time: 0.0034   lr: 0.002  max_mem: 3228M
[03/19 21:51:52] d2.utils.events INFO:  eta: 0:00:41  iter: 1059  total_loss: 0.942  loss_cls: 0.1908  loss_box_reg: 0.3638  loss_mask: 0.1987  loss_rpn_cls: 0.04702  loss_rpn_loc: 0.1076    time: 0.2898  last_time: 0.3011  data_time: 0.0034  last_data_time: 0.0036   lr: 0.002  max_mem: 3228M
[03/19 21:51:58] d2.utils.events INFO:  eta: 0:00:36  iter: 1079  total_loss: 0.9009  loss_cls: 0.2072  loss_box_reg: 0.3761  loss_mask: 0.1901  loss_rpn_cls: 0.04654  loss_rpn_loc: 0.1126    time: 0.2901  last_time: 0.3080  data_time: 0.0035  last_data_time: 0.0031   lr: 0.002  max_mem: 3228M
[03/19 21:52:01] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0001088.pth
[03/19 21:52:04] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:52:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:52:04] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:52:04] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:52:04] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:52:04] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:52:05] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0276 s/iter. Eval: 0.0061 s/iter. Total: 0.0341 s/iter. ETA=0:00:00
[03/19 21:52:05] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.561294 (0.037420 s / iter per device, on 1 devices)
[03/19 21:52:05] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.027679 s / iter per device, on 1 devices)
[03/19 21:52:05] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:52:05] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:52:05] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:52:05] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:52:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 21:52:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:52:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:52:05] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 57.539 | 91.580 | 64.779 | 49.307 | 62.838 | 68.633 |
[03/19 21:52:05] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 73.977 | weed       | 41.100 |
[03/19 21:52:05] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 21:52:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:52:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:52:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:52:05] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 60.301 | 92.853 | 68.405 | 48.495 | 66.883 | 70.891 |
[03/19 21:52:05] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 75.660 | weed       | 44.941 |
[03/19 21:52:05] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 21:52:05] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 21:52:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:52:05] d2.evaluation.testing INFO: copypaste: 57.5386,91.5795,64.7792,49.3071,62.8375,68.6331
[03/19 21:52:05] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 21:52:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:52:05] d2.evaluation.testing INFO: copypaste: 60.3007,92.8529,68.4052,48.4952,66.8831,70.8911
[03/19 21:52:05] d2.utils.events INFO:  eta: 0:00:30  iter: 1099  total_loss: 0.8799  loss_cls: 0.1976  loss_box_reg: 0.3441  loss_mask: 0.1813  loss_rpn_cls: 0.03365  loss_rpn_loc: 0.1015    time: 0.2904  last_time: 0.3045  data_time: 0.0032  last_data_time: 0.0034   lr: 0.002  max_mem: 3228M
[03/19 21:52:11] d2.utils.events INFO:  eta: 0:00:23  iter: 1119  total_loss: 0.9864  loss_cls: 0.193  loss_box_reg: 0.3943  loss_mask: 0.1812  loss_rpn_cls: 0.05108  loss_rpn_loc: 0.1299    time: 0.2906  last_time: 0.3128  data_time: 0.0033  last_data_time: 0.0029   lr: 0.002  max_mem: 3228M
[03/19 21:52:17] d2.utils.events INFO:  eta: 0:00:17  iter: 1139  total_loss: 0.8943  loss_cls: 0.1992  loss_box_reg: 0.3504  loss_mask: 0.185  loss_rpn_cls: 0.0407  loss_rpn_loc: 0.109    time: 0.2908  last_time: 0.3134  data_time: 0.0033  last_data_time: 0.0031   lr: 0.002  max_mem: 3228M
[03/19 21:52:23] d2.utils.events INFO:  eta: 0:00:11  iter: 1159  total_loss: 0.8377  loss_cls: 0.1867  loss_box_reg: 0.3334  loss_mask: 0.1707  loss_rpn_cls: 0.03418  loss_rpn_loc: 0.07922    time: 0.2911  last_time: 0.3457  data_time: 0.0031  last_data_time: 0.0034   lr: 0.002  max_mem: 3228M
[03/19 21:52:29] d2.utils.events INFO:  eta: 0:00:05  iter: 1179  total_loss: 0.9953  loss_cls: 0.1921  loss_box_reg: 0.3816  loss_mask: 0.1918  loss_rpn_cls: 0.06412  loss_rpn_loc: 0.1328    time: 0.2913  last_time: 0.3125  data_time: 0.0036  last_data_time: 0.0040   lr: 0.002  max_mem: 3228M
[03/19 21:52:32] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0001187.pth
[03/19 21:52:35] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_final.pth
[03/19 21:52:36] d2.utils.events INFO:  eta: 0:00:00  iter: 1198  total_loss: 0.9104  loss_cls: 0.1881  loss_box_reg: 0.3867  loss_mask: 0.1897  loss_rpn_cls: 0.04521  loss_rpn_loc: 0.1148    time: 0.2915  last_time: 0.3114  data_time: 0.0035  last_data_time: 0.0036   lr: 0.002  max_mem: 3228M
[03/19 21:52:36] d2.engine.hooks INFO: Overall training speed: 1197 iterations in 0:05:48 (0.2915 s / it)
[03/19 21:52:36] d2.engine.hooks INFO: Total training time: 0:06:04 (0:00:15 on hooks)
[03/19 21:52:36] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 21:52:36] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 21:52:36] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 21:52:36] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 21:52:36] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 21:52:36] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 21:52:36] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0005 s/iter. Inference: 0.0267 s/iter. Eval: 0.0068 s/iter. Total: 0.0340 s/iter. ETA=0:00:00
[03/19 21:52:36] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.567728 (0.037849 s / iter per device, on 1 devices)
[03/19 21:52:36] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.027415 s / iter per device, on 1 devices)
[03/19 21:52:36] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 21:52:36] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 21:52:36] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 21:52:36] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 21:52:36] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 21:52:36] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:52:36] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:52:36] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 58.574 | 91.112 | 65.134 | 53.689 | 61.546 | 73.621 |
[03/19 21:52:36] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 75.612 | weed       | 41.536 |
[03/19 21:52:36] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 21:52:36] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 21:52:36] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 21:52:36] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 21:52:36] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 62.089 | 91.276 | 72.108 | 55.871 | 68.970 | 75.743 |
[03/19 21:52:36] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 79.557 | weed       | 44.622 |
[03/19 21:52:36] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 21:52:36] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 21:52:36] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:52:36] d2.evaluation.testing INFO: copypaste: 58.5737,91.1125,65.1339,53.6886,61.5463,73.6206
[03/19 21:52:36] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 21:52:36] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 21:52:36] d2.evaluation.testing INFO: copypaste: 62.0893,91.2759,72.1083,55.8713,68.9703,75.7426
[03/19 22:16:12] detectron2 INFO: Rank of current process: 0. World size: 1
[03/19 22:16:12] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
numpy                            1.24.3
detectron2                       0.6 @/home/lu/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Ti (arch=8.6)
Driver version                   545.29.06
CUDA_HOME                        None - invalid!
Pillow                           10.2.0
torchvision                      0.17.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision
torchvision arch flags           /home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[03/19 22:16:12] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[03/19 22:16:12] detectron2 INFO: Contents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[03/19 22:16:12] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_my_val
  TRAIN:
  - coco_my_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 640
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 512
  - 768
  MIN_SIZE_TRAIN_SAMPLING: range
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 2
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 299
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 3599
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 7000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 300
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/19 22:16:12] detectron2 INFO: Full config saved to ./output/config.yaml
[03/19 22:16:12] d2.utils.env INFO: Using a generated random seed 13069442
[03/19 22:16:13] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/19 22:16:13] d2.data.datasets.coco INFO: Loaded 130 images in COCO format from /home/lu/detectron2/potato/COCOformat/train.json
[03/19 22:16:13] d2.data.build INFO: Removed 0 images with no usable annotations. 130 images left.
[03/19 22:16:13] d2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|   potato   | 659          |    weed    | 934          |
|            |              |            |              |
|   total    | 1593         |            |              |[0m
[03/19 22:16:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.9, 0.9]), ResizeShortestEdge(short_edge_length=(512, 768), max_size=640), RandomFlip()]
[03/19 22:16:13] d2.data.build INFO: Using training sampler TrainingSampler
[03/19 22:16:13] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:16:13] d2.data.common INFO: Serializing 130 elements to byte tensors and concatenating them all ...
[03/19 22:16:13] d2.data.common INFO: Serialized dataset takes 0.61 MiB
[03/19 22:16:13] d2.data.build INFO: Making batched data loader with batch_size=4
[03/19 22:16:13] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[03/19 22:16:13] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 22:16:13] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 22:16:13] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/19 22:16:13] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up - Total num: 54
[03/19 22:16:13] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.{bias, weight}[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[03/19 22:16:13] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/19 22:16:13] d2.engine.train_loop INFO: Starting training from iteration 0
[03/19 22:16:18] d2.utils.events INFO:  eta: 0:12:50  iter: 19  total_loss: 5.662  loss_cls: 3.988  loss_box_reg: 0.0759  loss_mask: 0.6927  loss_rpn_cls: 0.6667  loss_rpn_loc: 0.2667    time: 0.2155  last_time: 0.2244  data_time: 0.0111  last_data_time: 0.0034   lr: 3.9962e-05  max_mem: 2148M
[03/19 22:16:22] d2.utils.events INFO:  eta: 0:12:31  iter: 39  total_loss: 2.293  loss_cls: 0.5392  loss_box_reg: 0.06658  loss_mask: 0.6827  loss_rpn_cls: 0.647  loss_rpn_loc: 0.3104    time: 0.2136  last_time: 0.2013  data_time: 0.0032  last_data_time: 0.0028   lr: 7.9922e-05  max_mem: 2148M
[03/19 22:16:26] d2.utils.events INFO:  eta: 0:12:37  iter: 59  total_loss: 2.06  loss_cls: 0.4483  loss_box_reg: 0.06944  loss_mask: 0.6703  loss_rpn_cls: 0.5941  loss_rpn_loc: 0.262    time: 0.2158  last_time: 0.2220  data_time: 0.0032  last_data_time: 0.0032   lr: 0.00011988  max_mem: 2148M
[03/19 22:16:31] d2.utils.events INFO:  eta: 0:12:55  iter: 79  total_loss: 1.77  loss_cls: 0.2907  loss_box_reg: 0.09065  loss_mask: 0.6611  loss_rpn_cls: 0.5297  loss_rpn_loc: 0.2169    time: 0.2201  last_time: 0.2299  data_time: 0.0029  last_data_time: 0.0026   lr: 0.00015984  max_mem: 2148M
[03/19 22:16:36] d2.utils.events INFO:  eta: 0:13:01  iter: 99  total_loss: 1.833  loss_cls: 0.2797  loss_box_reg: 0.1496  loss_mask: 0.6438  loss_rpn_cls: 0.5138  loss_rpn_loc: 0.2821    time: 0.2226  last_time: 0.2160  data_time: 0.0032  last_data_time: 0.0028   lr: 0.0001998  max_mem: 2327M
[03/19 22:16:41] d2.utils.events INFO:  eta: 0:12:59  iter: 119  total_loss: 1.734  loss_cls: 0.2621  loss_box_reg: 0.2106  loss_mask: 0.6596  loss_rpn_cls: 0.4082  loss_rpn_loc: 0.1904    time: 0.2269  last_time: 0.3890  data_time: 0.0031  last_data_time: 0.0030   lr: 0.00023976  max_mem: 2397M
[03/19 22:16:45] d2.utils.events INFO:  eta: 0:12:55  iter: 139  total_loss: 1.697  loss_cls: 0.2561  loss_box_reg: 0.2386  loss_mask: 0.6401  loss_rpn_cls: 0.3229  loss_rpn_loc: 0.2105    time: 0.2272  last_time: 0.2454  data_time: 0.0034  last_data_time: 0.0031   lr: 0.00027972  max_mem: 2585M
[03/19 22:16:50] d2.utils.events INFO:  eta: 0:12:53  iter: 159  total_loss: 1.764  loss_cls: 0.2716  loss_box_reg: 0.3546  loss_mask: 0.638  loss_rpn_cls: 0.2393  loss_rpn_loc: 0.2241    time: 0.2283  last_time: 0.2419  data_time: 0.0034  last_data_time: 0.0033   lr: 0.00031968  max_mem: 2798M
[03/19 22:16:55] d2.utils.events INFO:  eta: 0:12:54  iter: 179  total_loss: 1.737  loss_cls: 0.3001  loss_box_reg: 0.475  loss_mask: 0.6412  loss_rpn_cls: 0.1899  loss_rpn_loc: 0.1966    time: 0.2309  last_time: 0.2399  data_time: 0.0031  last_data_time: 0.0031   lr: 0.00035964  max_mem: 2798M
[03/19 22:17:00] d2.utils.events INFO:  eta: 0:12:57  iter: 199  total_loss: 1.893  loss_cls: 0.3196  loss_box_reg: 0.5609  loss_mask: 0.6192  loss_rpn_cls: 0.1663  loss_rpn_loc: 0.2132    time: 0.2347  last_time: 0.2818  data_time: 0.0033  last_data_time: 0.0035   lr: 0.0003996  max_mem: 2892M
[03/19 22:17:06] d2.utils.events INFO:  eta: 0:12:59  iter: 219  total_loss: 1.836  loss_cls: 0.3333  loss_box_reg: 0.6207  loss_mask: 0.6041  loss_rpn_cls: 0.1145  loss_rpn_loc: 0.1566    time: 0.2383  last_time: 0.2702  data_time: 0.0032  last_data_time: 0.0036   lr: 0.00043956  max_mem: 2983M
[03/19 22:17:12] d2.utils.events INFO:  eta: 0:13:01  iter: 239  total_loss: 1.892  loss_cls: 0.3444  loss_box_reg: 0.6941  loss_mask: 0.5861  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.163    time: 0.2433  last_time: 0.2787  data_time: 0.0033  last_data_time: 0.0036   lr: 0.00047952  max_mem: 3224M
[03/19 22:17:18] d2.utils.events INFO:  eta: 0:13:09  iter: 259  total_loss: 1.789  loss_cls: 0.3185  loss_box_reg: 0.6349  loss_mask: 0.5447  loss_rpn_cls: 0.1148  loss_rpn_loc: 0.1864    time: 0.2481  last_time: 0.3086  data_time: 0.0032  last_data_time: 0.0031   lr: 0.00051948  max_mem: 3224M
[03/19 22:17:24] d2.utils.events INFO:  eta: 0:13:18  iter: 279  total_loss: 1.738  loss_cls: 0.3223  loss_box_reg: 0.6652  loss_mask: 0.4838  loss_rpn_cls: 0.08735  loss_rpn_loc: 0.1573    time: 0.2522  last_time: 0.3131  data_time: 0.0035  last_data_time: 0.0041   lr: 0.00055944  max_mem: 3225M
[03/19 22:17:30] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000298.pth
[03/19 22:17:30] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 22:17:30] d2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|   potato   | 82           |    weed    | 138          |
|            |              |            |              |
|   total    | 220          |            |              |[0m
[03/19 22:17:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 22:17:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:17:30] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 22:17:30] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 22:17:30] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 22:17:31] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0297 s/iter. Eval: 0.0126 s/iter. Total: 0.0428 s/iter. ETA=0:00:00
[03/19 22:17:31] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.709638 (0.047309 s / iter per device, on 1 devices)
[03/19 22:17:31] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.031271 s / iter per device, on 1 devices)
[03/19 22:17:31] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 22:17:31] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 22:17:32] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 22:17:32] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 22:17:32] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:17:32] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:17:32] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:17:32] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 34.495 | 73.855 | 28.053 | 31.810 | 34.688 | 44.952 |
[03/19 22:17:32] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 50.766 | weed       | 18.223 |
[03/19 22:17:32] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 22:17:32] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 22:17:32] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:17:32] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:17:32] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 33.561 | 73.178 | 25.214 | 25.714 | 39.952 | 49.691 |
[03/19 22:17:32] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 49.549 | weed       | 17.573 |
[03/19 22:17:32] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 22:17:32] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 22:17:32] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:17:32] d2.evaluation.testing INFO: copypaste: 34.4948,73.8554,28.0532,31.8100,34.6884,44.9516
[03/19 22:17:32] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 22:17:32] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:17:32] d2.evaluation.testing INFO: copypaste: 33.5611,73.1780,25.2137,25.7141,39.9516,49.6906
[03/19 22:17:32] d2.utils.events INFO:  eta: 0:13:26  iter: 299  total_loss: 1.648  loss_cls: 0.366  loss_box_reg: 0.6082  loss_mask: 0.4281  loss_rpn_cls: 0.09814  loss_rpn_loc: 0.1871    time: 0.2554  last_time: 0.2978  data_time: 0.0032  last_data_time: 0.0033   lr: 0.0005994  max_mem: 3226M
[03/19 22:17:38] d2.utils.events INFO:  eta: 0:13:46  iter: 319  total_loss: 1.569  loss_cls: 0.3388  loss_box_reg: 0.6138  loss_mask: 0.3772  loss_rpn_cls: 0.0821  loss_rpn_loc: 0.1395    time: 0.2583  last_time: 0.3042  data_time: 0.0033  last_data_time: 0.0033   lr: 0.00063936  max_mem: 3226M
[03/19 22:17:44] d2.utils.events INFO:  eta: 0:13:53  iter: 339  total_loss: 1.501  loss_cls: 0.3183  loss_box_reg: 0.5848  loss_mask: 0.3539  loss_rpn_cls: 0.09865  loss_rpn_loc: 0.1742    time: 0.2608  last_time: 0.2966  data_time: 0.0030  last_data_time: 0.0032   lr: 0.00067932  max_mem: 3226M
[03/19 22:17:50] d2.utils.events INFO:  eta: 0:14:06  iter: 359  total_loss: 1.504  loss_cls: 0.342  loss_box_reg: 0.5851  loss_mask: 0.3113  loss_rpn_cls: 0.07712  loss_rpn_loc: 0.1623    time: 0.2632  last_time: 0.3064  data_time: 0.0030  last_data_time: 0.0031   lr: 0.00071928  max_mem: 3227M
[03/19 22:17:56] d2.utils.events INFO:  eta: 0:14:29  iter: 379  total_loss: 1.483  loss_cls: 0.3151  loss_box_reg: 0.5512  loss_mask: 0.299  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.1855    time: 0.2653  last_time: 0.2812  data_time: 0.0031  last_data_time: 0.0032   lr: 0.00075924  max_mem: 3227M
[03/19 22:18:02] d2.utils.events INFO:  eta: 0:14:35  iter: 399  total_loss: 1.374  loss_cls: 0.307  loss_box_reg: 0.5387  loss_mask: 0.2902  loss_rpn_cls: 0.07351  loss_rpn_loc: 0.1791    time: 0.2673  last_time: 0.3029  data_time: 0.0033  last_data_time: 0.0030   lr: 0.0007992  max_mem: 3227M
[03/19 22:18:08] d2.utils.events INFO:  eta: 0:14:39  iter: 419  total_loss: 1.349  loss_cls: 0.3228  loss_box_reg: 0.5161  loss_mask: 0.2732  loss_rpn_cls: 0.0701  loss_rpn_loc: 0.1434    time: 0.2691  last_time: 0.3147  data_time: 0.0029  last_data_time: 0.0026   lr: 0.00083916  max_mem: 3227M
[03/19 22:18:14] d2.utils.events INFO:  eta: 0:14:45  iter: 439  total_loss: 1.326  loss_cls: 0.2855  loss_box_reg: 0.5012  loss_mask: 0.2742  loss_rpn_cls: 0.07068  loss_rpn_loc: 0.161    time: 0.2705  last_time: 0.3008  data_time: 0.0031  last_data_time: 0.0028   lr: 0.00087912  max_mem: 3227M
[03/19 22:18:20] d2.utils.events INFO:  eta: 0:14:47  iter: 459  total_loss: 1.234  loss_cls: 0.2966  loss_box_reg: 0.484  loss_mask: 0.2545  loss_rpn_cls: 0.08066  loss_rpn_loc: 0.1521    time: 0.2721  last_time: 0.3102  data_time: 0.0031  last_data_time: 0.0033   lr: 0.00091908  max_mem: 3227M
[03/19 22:18:27] d2.utils.events INFO:  eta: 0:14:47  iter: 479  total_loss: 1.229  loss_cls: 0.2922  loss_box_reg: 0.4836  loss_mask: 0.25  loss_rpn_cls: 0.05118  loss_rpn_loc: 0.1353    time: 0.2744  last_time: 0.3314  data_time: 0.0032  last_data_time: 0.0036   lr: 0.00095904  max_mem: 3227M
[03/19 22:18:33] d2.utils.events INFO:  eta: 0:14:56  iter: 499  total_loss: 1.208  loss_cls: 0.2892  loss_box_reg: 0.4966  loss_mask: 0.2388  loss_rpn_cls: 0.05847  loss_rpn_loc: 0.1145    time: 0.2759  last_time: 0.3009  data_time: 0.0032  last_data_time: 0.0030   lr: 0.000999  max_mem: 3227M
[03/19 22:18:39] d2.utils.events INFO:  eta: 0:14:56  iter: 519  total_loss: 1.167  loss_cls: 0.2739  loss_box_reg: 0.4599  loss_mask: 0.2367  loss_rpn_cls: 0.0635  loss_rpn_loc: 0.1379    time: 0.2772  last_time: 0.3103  data_time: 0.0032  last_data_time: 0.0033   lr: 0.001039  max_mem: 3227M
[03/19 22:18:45] d2.utils.events INFO:  eta: 0:14:54  iter: 539  total_loss: 1.169  loss_cls: 0.2619  loss_box_reg: 0.4594  loss_mask: 0.2234  loss_rpn_cls: 0.06904  loss_rpn_loc: 0.1491    time: 0.2783  last_time: 0.3112  data_time: 0.0031  last_data_time: 0.0027   lr: 0.0010789  max_mem: 3227M
[03/19 22:18:52] d2.utils.events INFO:  eta: 0:14:54  iter: 559  total_loss: 1.124  loss_cls: 0.2767  loss_box_reg: 0.4668  loss_mask: 0.2316  loss_rpn_cls: 0.0574  loss_rpn_loc: 0.1175    time: 0.2798  last_time: 0.3114  data_time: 0.0029  last_data_time: 0.0029   lr: 0.0011189  max_mem: 3227M
[03/19 22:18:58] d2.utils.events INFO:  eta: 0:14:52  iter: 579  total_loss: 1.134  loss_cls: 0.2646  loss_box_reg: 0.4423  loss_mask: 0.2241  loss_rpn_cls: 0.06617  loss_rpn_loc: 0.1184    time: 0.2807  last_time: 0.3166  data_time: 0.0035  last_data_time: 0.0031   lr: 0.0011588  max_mem: 3227M
[03/19 22:19:03] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000597.pth
[03/19 22:19:04] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 22:19:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 22:19:04] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:19:04] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 22:19:04] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 22:19:04] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 22:19:05] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0296 s/iter. Eval: 0.0094 s/iter. Total: 0.0393 s/iter. ETA=0:00:00
[03/19 22:19:05] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.645141 (0.043009 s / iter per device, on 1 devices)
[03/19 22:19:05] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.029549 s / iter per device, on 1 devices)
[03/19 22:19:05] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 22:19:05] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 22:19:05] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 22:19:05] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 22:19:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:19:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:19:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:19:05] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.544 | 91.105 | 63.041 | 47.829 | 55.534 | 67.622 |
[03/19 22:19:05] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 69.398 | weed       | 37.690 |
[03/19 22:19:05] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 22:19:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 22:19:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:19:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:19:05] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 54.709 | 90.729 | 60.737 | 48.227 | 61.548 | 67.525 |
[03/19 22:19:05] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 72.857 | weed       | 36.561 |
[03/19 22:19:05] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 22:19:05] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 22:19:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:19:05] d2.evaluation.testing INFO: copypaste: 53.5438,91.1051,63.0406,47.8291,55.5337,67.6221
[03/19 22:19:05] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 22:19:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:19:05] d2.evaluation.testing INFO: copypaste: 54.7089,90.7285,60.7367,48.2265,61.5477,67.5248
[03/19 22:19:05] d2.utils.events INFO:  eta: 0:14:51  iter: 599  total_loss: 1.091  loss_cls: 0.2587  loss_box_reg: 0.4447  loss_mask: 0.2172  loss_rpn_cls: 0.04769  loss_rpn_loc: 0.1164    time: 0.2816  last_time: 0.3144  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0011988  max_mem: 3227M
[03/19 22:19:11] d2.utils.events INFO:  eta: 0:14:48  iter: 619  total_loss: 1.125  loss_cls: 0.2752  loss_box_reg: 0.4566  loss_mask: 0.2177  loss_rpn_cls: 0.05915  loss_rpn_loc: 0.126    time: 0.2823  last_time: 0.2999  data_time: 0.0033  last_data_time: 0.0037   lr: 0.0012388  max_mem: 3227M
[03/19 22:19:17] d2.utils.events INFO:  eta: 0:14:42  iter: 639  total_loss: 1.063  loss_cls: 0.254  loss_box_reg: 0.4126  loss_mask: 0.2134  loss_rpn_cls: 0.04387  loss_rpn_loc: 0.1169    time: 0.2829  last_time: 0.3154  data_time: 0.0031  last_data_time: 0.0033   lr: 0.0012787  max_mem: 3227M
[03/19 22:19:23] d2.utils.events INFO:  eta: 0:14:37  iter: 659  total_loss: 1.097  loss_cls: 0.2601  loss_box_reg: 0.4445  loss_mask: 0.2159  loss_rpn_cls: 0.06062  loss_rpn_loc: 0.1382    time: 0.2837  last_time: 0.2959  data_time: 0.0033  last_data_time: 0.0029   lr: 0.0013187  max_mem: 3227M
[03/19 22:19:30] d2.utils.events INFO:  eta: 0:14:32  iter: 679  total_loss: 1.117  loss_cls: 0.2433  loss_box_reg: 0.4404  loss_mask: 0.2251  loss_rpn_cls: 0.0715  loss_rpn_loc: 0.1366    time: 0.2844  last_time: 0.2640  data_time: 0.0034  last_data_time: 0.0036   lr: 0.0013586  max_mem: 3227M
[03/19 22:19:36] d2.utils.events INFO:  eta: 0:14:27  iter: 699  total_loss: 1.091  loss_cls: 0.2595  loss_box_reg: 0.4305  loss_mask: 0.2197  loss_rpn_cls: 0.06199  loss_rpn_loc: 0.1256    time: 0.2850  last_time: 0.3136  data_time: 0.0033  last_data_time: 0.0030   lr: 0.0013986  max_mem: 3227M
[03/19 22:19:42] d2.utils.events INFO:  eta: 0:14:22  iter: 719  total_loss: 1.131  loss_cls: 0.2576  loss_box_reg: 0.4441  loss_mask: 0.2175  loss_rpn_cls: 0.06538  loss_rpn_loc: 0.1216    time: 0.2856  last_time: 0.3124  data_time: 0.0032  last_data_time: 0.0034   lr: 0.0014386  max_mem: 3227M
[03/19 22:19:48] d2.utils.events INFO:  eta: 0:14:17  iter: 739  total_loss: 1.033  loss_cls: 0.228  loss_box_reg: 0.4113  loss_mask: 0.2065  loss_rpn_cls: 0.07473  loss_rpn_loc: 0.1216    time: 0.2863  last_time: 0.3013  data_time: 0.0031  last_data_time: 0.0031   lr: 0.0014785  max_mem: 3227M
[03/19 22:19:54] d2.utils.events INFO:  eta: 0:14:12  iter: 759  total_loss: 0.9803  loss_cls: 0.2319  loss_box_reg: 0.4233  loss_mask: 0.2046  loss_rpn_cls: 0.04763  loss_rpn_loc: 0.1162    time: 0.2868  last_time: 0.3201  data_time: 0.0033  last_data_time: 0.0034   lr: 0.0015185  max_mem: 3227M
[03/19 22:20:01] d2.utils.events INFO:  eta: 0:14:08  iter: 779  total_loss: 1.046  loss_cls: 0.2466  loss_box_reg: 0.4198  loss_mask: 0.2049  loss_rpn_cls: 0.05282  loss_rpn_loc: 0.1323    time: 0.2878  last_time: 0.3264  data_time: 0.0034  last_data_time: 0.0032   lr: 0.0015584  max_mem: 3227M
[03/19 22:20:07] d2.utils.events INFO:  eta: 0:14:03  iter: 799  total_loss: 1.001  loss_cls: 0.2421  loss_box_reg: 0.4162  loss_mask: 0.1983  loss_rpn_cls: 0.04525  loss_rpn_loc: 0.1274    time: 0.2885  last_time: 0.3239  data_time: 0.0032  last_data_time: 0.0025   lr: 0.0015984  max_mem: 3227M
[03/19 22:20:14] d2.utils.events INFO:  eta: 0:13:59  iter: 819  total_loss: 1.005  loss_cls: 0.2212  loss_box_reg: 0.4249  loss_mask: 0.2041  loss_rpn_cls: 0.05232  loss_rpn_loc: 0.09963    time: 0.2894  last_time: 0.3453  data_time: 0.0030  last_data_time: 0.0033   lr: 0.0016384  max_mem: 3227M
[03/19 22:20:20] d2.utils.events INFO:  eta: 0:13:55  iter: 839  total_loss: 1.041  loss_cls: 0.2564  loss_box_reg: 0.4133  loss_mask: 0.2087  loss_rpn_cls: 0.04096  loss_rpn_loc: 0.118    time: 0.2904  last_time: 0.3336  data_time: 0.0032  last_data_time: 0.0030   lr: 0.0016783  max_mem: 3227M
[03/19 22:20:26] d2.utils.events INFO:  eta: 0:13:49  iter: 859  total_loss: 0.9755  loss_cls: 0.2272  loss_box_reg: 0.3978  loss_mask: 0.2032  loss_rpn_cls: 0.05036  loss_rpn_loc: 0.09428    time: 0.2909  last_time: 0.2951  data_time: 0.0032  last_data_time: 0.0033   lr: 0.0017183  max_mem: 3227M
[03/19 22:20:33] d2.utils.events INFO:  eta: 0:13:44  iter: 879  total_loss: 1.045  loss_cls: 0.2511  loss_box_reg: 0.4146  loss_mask: 0.2015  loss_rpn_cls: 0.04688  loss_rpn_loc: 0.1165    time: 0.2912  last_time: 0.3148  data_time: 0.0032  last_data_time: 0.0035   lr: 0.0017582  max_mem: 3227M
[03/19 22:20:38] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0000896.pth
[03/19 22:20:39] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 22:20:39] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 22:20:39] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:20:39] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 22:20:39] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 22:20:39] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 22:20:40] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0284 s/iter. Eval: 0.0078 s/iter. Total: 0.0366 s/iter. ETA=0:00:00
[03/19 22:20:40] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.596824 (0.039788 s / iter per device, on 1 devices)
[03/19 22:20:40] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.028512 s / iter per device, on 1 devices)
[03/19 22:20:40] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 22:20:40] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 22:20:40] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 22:20:40] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 22:20:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:20:40] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:20:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:20:40] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 57.645 | 91.427 | 59.744 | 54.698 | 54.400 | 63.499 |
[03/19 22:20:40] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 74.733 | weed       | 40.557 |
[03/19 22:20:40] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 22:20:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 22:20:40] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:20:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:20:40] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 57.379 | 92.022 | 65.318 | 54.331 | 63.360 | 67.426 |
[03/19 22:20:40] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 74.192 | weed       | 40.566 |
[03/19 22:20:40] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 22:20:40] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 22:20:40] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:20:40] d2.evaluation.testing INFO: copypaste: 57.6446,91.4272,59.7437,54.6977,54.4003,63.4994
[03/19 22:20:40] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 22:20:40] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:20:40] d2.evaluation.testing INFO: copypaste: 57.3789,92.0218,65.3180,54.3306,63.3595,67.4257
[03/19 22:20:40] d2.utils.events INFO:  eta: 0:13:38  iter: 899  total_loss: 0.9572  loss_cls: 0.2163  loss_box_reg: 0.3854  loss_mask: 0.1928  loss_rpn_cls: 0.04756  loss_rpn_loc: 0.1114    time: 0.2916  last_time: 0.3108  data_time: 0.0032  last_data_time: 0.0037   lr: 0.0017982  max_mem: 3227M
[03/19 22:20:46] d2.utils.events INFO:  eta: 0:13:33  iter: 919  total_loss: 1.064  loss_cls: 0.263  loss_box_reg: 0.412  loss_mask: 0.2101  loss_rpn_cls: 0.05864  loss_rpn_loc: 0.1136    time: 0.2921  last_time: 0.3184  data_time: 0.0030  last_data_time: 0.0031   lr: 0.0018382  max_mem: 3227M
[03/19 22:20:52] d2.utils.events INFO:  eta: 0:13:27  iter: 939  total_loss: 0.9381  loss_cls: 0.2108  loss_box_reg: 0.3746  loss_mask: 0.1985  loss_rpn_cls: 0.04414  loss_rpn_loc: 0.1092    time: 0.2925  last_time: 0.3105  data_time: 0.0032  last_data_time: 0.0033   lr: 0.0018781  max_mem: 3227M
[03/19 22:20:59] d2.utils.events INFO:  eta: 0:13:22  iter: 959  total_loss: 0.9027  loss_cls: 0.2173  loss_box_reg: 0.3593  loss_mask: 0.1846  loss_rpn_cls: 0.03693  loss_rpn_loc: 0.1001    time: 0.2928  last_time: 0.3113  data_time: 0.0032  last_data_time: 0.0032   lr: 0.0019181  max_mem: 3227M
[03/19 22:21:05] d2.utils.events INFO:  eta: 0:13:17  iter: 979  total_loss: 0.9919  loss_cls: 0.2215  loss_box_reg: 0.3914  loss_mask: 0.1967  loss_rpn_cls: 0.04339  loss_rpn_loc: 0.1252    time: 0.2934  last_time: 0.3347  data_time: 0.0031  last_data_time: 0.0029   lr: 0.001958  max_mem: 3227M
[03/19 22:21:12] d2.utils.events INFO:  eta: 0:13:12  iter: 999  total_loss: 0.9879  loss_cls: 0.2097  loss_box_reg: 0.4024  loss_mask: 0.1932  loss_rpn_cls: 0.05088  loss_rpn_loc: 0.1222    time: 0.2940  last_time: 0.3358  data_time: 0.0032  last_data_time: 0.0037   lr: 0.001998  max_mem: 3227M
[03/19 22:21:18] d2.utils.events INFO:  eta: 0:13:07  iter: 1019  total_loss: 0.9082  loss_cls: 0.1994  loss_box_reg: 0.3569  loss_mask: 0.1913  loss_rpn_cls: 0.0455  loss_rpn_loc: 0.08106    time: 0.2943  last_time: 0.3098  data_time: 0.0034  last_data_time: 0.0032   lr: 0.002  max_mem: 3227M
[03/19 22:21:24] d2.utils.events INFO:  eta: 0:13:03  iter: 1039  total_loss: 0.9882  loss_cls: 0.2205  loss_box_reg: 0.3981  loss_mask: 0.189  loss_rpn_cls: 0.04501  loss_rpn_loc: 0.1036    time: 0.2946  last_time: 0.3036  data_time: 0.0031  last_data_time: 0.0033   lr: 0.002  max_mem: 3227M
[03/19 22:21:30] d2.utils.events INFO:  eta: 0:12:59  iter: 1059  total_loss: 0.9128  loss_cls: 0.201  loss_box_reg: 0.3671  loss_mask: 0.1905  loss_rpn_cls: 0.05431  loss_rpn_loc: 0.09691    time: 0.2948  last_time: 0.3114  data_time: 0.0032  last_data_time: 0.0029   lr: 0.002  max_mem: 3227M
[03/19 22:21:36] d2.utils.events INFO:  eta: 0:12:54  iter: 1079  total_loss: 0.9392  loss_cls: 0.2145  loss_box_reg: 0.3674  loss_mask: 0.1861  loss_rpn_cls: 0.04324  loss_rpn_loc: 0.1261    time: 0.2950  last_time: 0.3247  data_time: 0.0030  last_data_time: 0.0027   lr: 0.002  max_mem: 3227M
[03/19 22:21:42] d2.utils.events INFO:  eta: 0:12:50  iter: 1099  total_loss: 0.9582  loss_cls: 0.2234  loss_box_reg: 0.3706  loss_mask: 0.1773  loss_rpn_cls: 0.04772  loss_rpn_loc: 0.1114    time: 0.2952  last_time: 0.3031  data_time: 0.0031  last_data_time: 0.0029   lr: 0.002  max_mem: 3227M
[03/19 22:21:48] d2.utils.events INFO:  eta: 0:12:45  iter: 1119  total_loss: 0.9637  loss_cls: 0.1975  loss_box_reg: 0.3933  loss_mask: 0.1965  loss_rpn_cls: 0.04384  loss_rpn_loc: 0.1284    time: 0.2954  last_time: 0.3124  data_time: 0.0031  last_data_time: 0.0030   lr: 0.002  max_mem: 3227M
[03/19 22:21:55] d2.utils.events INFO:  eta: 0:12:39  iter: 1139  total_loss: 0.9459  loss_cls: 0.2101  loss_box_reg: 0.3667  loss_mask: 0.1848  loss_rpn_cls: 0.05362  loss_rpn_loc: 0.1129    time: 0.2956  last_time: 0.3527  data_time: 0.0033  last_data_time: 0.0038   lr: 0.002  max_mem: 3227M
[03/19 22:22:01] d2.utils.events INFO:  eta: 0:12:34  iter: 1159  total_loss: 0.9192  loss_cls: 0.1952  loss_box_reg: 0.3551  loss_mask: 0.1848  loss_rpn_cls: 0.04914  loss_rpn_loc: 0.1159    time: 0.2960  last_time: 0.3305  data_time: 0.0037  last_data_time: 0.0034   lr: 0.002  max_mem: 3227M
[03/19 22:22:07] d2.utils.events INFO:  eta: 0:12:29  iter: 1179  total_loss: 0.865  loss_cls: 0.1894  loss_box_reg: 0.3364  loss_mask: 0.1746  loss_rpn_cls: 0.04213  loss_rpn_loc: 0.1168    time: 0.2963  last_time: 0.3124  data_time: 0.0033  last_data_time: 0.0032   lr: 0.002  max_mem: 3227M
[03/19 22:22:12] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0001195.pth
[03/19 22:22:13] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 22:22:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 22:22:13] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:22:13] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 22:22:13] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 22:22:13] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 22:22:14] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0005 s/iter. Inference: 0.0278 s/iter. Eval: 0.0066 s/iter. Total: 0.0349 s/iter. ETA=0:00:00
[03/19 22:22:14] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.567110 (0.037807 s / iter per device, on 1 devices)
[03/19 22:22:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.028033 s / iter per device, on 1 devices)
[03/19 22:22:14] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 22:22:14] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 22:22:14] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 22:22:14] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 22:22:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:22:14] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:22:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:22:14] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 58.306 | 92.112 | 64.324 | 55.077 | 60.022 | 60.517 |
[03/19 22:22:14] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 72.397 | weed       | 44.214 |
[03/19 22:22:14] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 22:22:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 22:22:14] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:22:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:22:14] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 62.048 | 91.710 | 71.922 | 55.132 | 68.235 | 72.079 |
[03/19 22:22:14] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 78.878 | weed       | 45.217 |
[03/19 22:22:14] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 22:22:14] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 22:22:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:22:14] d2.evaluation.testing INFO: copypaste: 58.3057,92.1120,64.3240,55.0771,60.0225,60.5172
[03/19 22:22:14] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 22:22:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:22:14] d2.evaluation.testing INFO: copypaste: 62.0475,91.7103,71.9221,55.1319,68.2346,72.0792
[03/19 22:22:14] d2.utils.events INFO:  eta: 0:12:23  iter: 1199  total_loss: 0.8688  loss_cls: 0.1776  loss_box_reg: 0.3372  loss_mask: 0.1922  loss_rpn_cls: 0.04955  loss_rpn_loc: 0.1223    time: 0.2962  last_time: 0.2904  data_time: 0.0032  last_data_time: 0.0028   lr: 0.002  max_mem: 3227M
[03/19 22:22:20] d2.utils.events INFO:  eta: 0:12:17  iter: 1219  total_loss: 0.8762  loss_cls: 0.1798  loss_box_reg: 0.3694  loss_mask: 0.1871  loss_rpn_cls: 0.04353  loss_rpn_loc: 0.105    time: 0.2963  last_time: 0.3161  data_time: 0.0033  last_data_time: 0.0034   lr: 0.002  max_mem: 3227M
[03/19 22:22:26] d2.utils.events INFO:  eta: 0:12:11  iter: 1239  total_loss: 0.9003  loss_cls: 0.2018  loss_box_reg: 0.3435  loss_mask: 0.1716  loss_rpn_cls: 0.03605  loss_rpn_loc: 0.1052    time: 0.2965  last_time: 0.3127  data_time: 0.0034  last_data_time: 0.0033   lr: 0.002  max_mem: 3227M
[03/19 22:22:33] d2.utils.events INFO:  eta: 0:12:05  iter: 1259  total_loss: 0.8324  loss_cls: 0.1843  loss_box_reg: 0.3252  loss_mask: 0.1748  loss_rpn_cls: 0.03505  loss_rpn_loc: 0.08306    time: 0.2967  last_time: 0.2819  data_time: 0.0028  last_data_time: 0.0032   lr: 0.002  max_mem: 3227M
[03/19 22:22:39] d2.utils.events INFO:  eta: 0:11:59  iter: 1279  total_loss: 0.8178  loss_cls: 0.193  loss_box_reg: 0.3384  loss_mask: 0.1782  loss_rpn_cls: 0.03851  loss_rpn_loc: 0.08808    time: 0.2968  last_time: 0.3054  data_time: 0.0032  last_data_time: 0.0030   lr: 0.002  max_mem: 3227M
[03/19 22:22:45] d2.utils.events INFO:  eta: 0:11:53  iter: 1299  total_loss: 0.8695  loss_cls: 0.1828  loss_box_reg: 0.3494  loss_mask: 0.1908  loss_rpn_cls: 0.03549  loss_rpn_loc: 0.09754    time: 0.2969  last_time: 0.3098  data_time: 0.0032  last_data_time: 0.0032   lr: 0.002  max_mem: 3227M
[03/19 22:22:51] d2.utils.events INFO:  eta: 0:11:47  iter: 1319  total_loss: 0.8508  loss_cls: 0.1783  loss_box_reg: 0.3531  loss_mask: 0.1782  loss_rpn_cls: 0.03329  loss_rpn_loc: 0.08634    time: 0.2970  last_time: 0.3116  data_time: 0.0032  last_data_time: 0.0029   lr: 0.002  max_mem: 3227M
[03/19 22:22:57] d2.utils.events INFO:  eta: 0:11:41  iter: 1339  total_loss: 0.9058  loss_cls: 0.1934  loss_box_reg: 0.3491  loss_mask: 0.1855  loss_rpn_cls: 0.03791  loss_rpn_loc: 0.115    time: 0.2971  last_time: 0.2965  data_time: 0.0033  last_data_time: 0.0035   lr: 0.002  max_mem: 3227M
[03/19 22:23:03] d2.utils.events INFO:  eta: 0:11:35  iter: 1359  total_loss: 0.8181  loss_cls: 0.1778  loss_box_reg: 0.3388  loss_mask: 0.171  loss_rpn_cls: 0.03286  loss_rpn_loc: 0.08691    time: 0.2972  last_time: 0.3034  data_time: 0.0033  last_data_time: 0.0034   lr: 0.002  max_mem: 3227M
[03/19 22:23:09] d2.utils.events INFO:  eta: 0:11:29  iter: 1379  total_loss: 0.8502  loss_cls: 0.188  loss_box_reg: 0.3331  loss_mask: 0.1747  loss_rpn_cls: 0.03771  loss_rpn_loc: 0.107    time: 0.2974  last_time: 0.2994  data_time: 0.0033  last_data_time: 0.0034   lr: 0.002  max_mem: 3227M
[03/19 22:23:15] d2.utils.events INFO:  eta: 0:11:23  iter: 1399  total_loss: 0.8395  loss_cls: 0.1796  loss_box_reg: 0.3317  loss_mask: 0.1771  loss_rpn_cls: 0.03568  loss_rpn_loc: 0.1125    time: 0.2975  last_time: 0.3138  data_time: 0.0035  last_data_time: 0.0036   lr: 0.002  max_mem: 3227M
[03/19 22:23:21] d2.utils.events INFO:  eta: 0:11:17  iter: 1419  total_loss: 0.8434  loss_cls: 0.1687  loss_box_reg: 0.367  loss_mask: 0.1761  loss_rpn_cls: 0.03593  loss_rpn_loc: 0.08867    time: 0.2976  last_time: 0.3486  data_time: 0.0033  last_data_time: 0.0041   lr: 0.002  max_mem: 3227M
[03/19 22:23:27] d2.utils.events INFO:  eta: 0:11:11  iter: 1439  total_loss: 0.8546  loss_cls: 0.1659  loss_box_reg: 0.322  loss_mask: 0.181  loss_rpn_cls: 0.04085  loss_rpn_loc: 0.1015    time: 0.2976  last_time: 0.3041  data_time: 0.0033  last_data_time: 0.0030   lr: 0.002  max_mem: 3227M
[03/19 22:23:33] d2.utils.events INFO:  eta: 0:11:04  iter: 1459  total_loss: 0.8737  loss_cls: 0.1929  loss_box_reg: 0.3436  loss_mask: 0.1767  loss_rpn_cls: 0.03984  loss_rpn_loc: 0.1011    time: 0.2977  last_time: 0.2827  data_time: 0.0028  last_data_time: 0.0028   lr: 0.002  max_mem: 3227M
[03/19 22:23:40] d2.utils.events INFO:  eta: 0:10:57  iter: 1479  total_loss: 0.8535  loss_cls: 0.1738  loss_box_reg: 0.3425  loss_mask: 0.1787  loss_rpn_cls: 0.04622  loss_rpn_loc: 0.107    time: 0.2977  last_time: 0.3126  data_time: 0.0031  last_data_time: 0.0030   lr: 0.002  max_mem: 3227M
[03/19 22:23:44] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0001494.pth
[03/19 22:23:46] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 22:23:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 22:23:46] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:23:46] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 22:23:46] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 22:23:46] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 22:23:46] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0263 s/iter. Eval: 0.0063 s/iter. Total: 0.0330 s/iter. ETA=0:00:00
[03/19 22:23:47] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.552854 (0.036857 s / iter per device, on 1 devices)
[03/19 22:23:47] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.027386 s / iter per device, on 1 devices)
[03/19 22:23:47] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 22:23:47] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 22:23:47] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 22:23:47] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 22:23:47] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:23:47] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:23:47] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:23:47] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 59.900 | 92.035 | 69.830 | 55.179 | 59.259 | 69.967 |
[03/19 22:23:47] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 74.484 | weed       | 45.316 |
[03/19 22:23:47] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 22:23:47] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 22:23:47] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:23:47] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:23:47] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 62.994 | 91.798 | 72.912 | 56.044 | 66.088 | 75.700 |
[03/19 22:23:47] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 79.513 | weed       | 46.475 |
[03/19 22:23:47] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 22:23:47] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 22:23:47] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:23:47] d2.evaluation.testing INFO: copypaste: 59.8999,92.0347,69.8305,55.1788,59.2587,69.9670
[03/19 22:23:47] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 22:23:47] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:23:47] d2.evaluation.testing INFO: copypaste: 62.9938,91.7982,72.9115,56.0442,66.0880,75.7001
[03/19 22:23:47] d2.utils.events INFO:  eta: 0:10:50  iter: 1499  total_loss: 0.7767  loss_cls: 0.1629  loss_box_reg: 0.3128  loss_mask: 0.1695  loss_rpn_cls: 0.02906  loss_rpn_loc: 0.08505    time: 0.2978  last_time: 0.3092  data_time: 0.0033  last_data_time: 0.0035   lr: 0.002  max_mem: 3227M
[03/19 22:23:53] d2.utils.events INFO:  eta: 0:10:44  iter: 1519  total_loss: 0.8504  loss_cls: 0.1862  loss_box_reg: 0.3284  loss_mask: 0.1818  loss_rpn_cls: 0.03485  loss_rpn_loc: 0.09662    time: 0.2979  last_time: 0.3079  data_time: 0.0033  last_data_time: 0.0033   lr: 0.002  max_mem: 3227M
[03/19 22:23:59] d2.utils.events INFO:  eta: 0:10:38  iter: 1539  total_loss: 0.8  loss_cls: 0.1758  loss_box_reg: 0.3384  loss_mask: 0.1857  loss_rpn_cls: 0.03618  loss_rpn_loc: 0.08934    time: 0.2980  last_time: 0.3143  data_time: 0.0032  last_data_time: 0.0030   lr: 0.002  max_mem: 3227M
[03/19 22:24:05] d2.utils.events INFO:  eta: 0:10:31  iter: 1559  total_loss: 0.8123  loss_cls: 0.1663  loss_box_reg: 0.3072  loss_mask: 0.1612  loss_rpn_cls: 0.03167  loss_rpn_loc: 0.07693    time: 0.2980  last_time: 0.2952  data_time: 0.0031  last_data_time: 0.0029   lr: 0.002  max_mem: 3227M
[03/19 22:24:11] d2.utils.events INFO:  eta: 0:10:24  iter: 1579  total_loss: 0.7642  loss_cls: 0.1583  loss_box_reg: 0.3169  loss_mask: 0.1794  loss_rpn_cls: 0.03305  loss_rpn_loc: 0.07723    time: 0.2980  last_time: 0.2769  data_time: 0.0029  last_data_time: 0.0030   lr: 0.002  max_mem: 3227M
[03/19 22:24:17] d2.utils.events INFO:  eta: 0:10:18  iter: 1599  total_loss: 0.7394  loss_cls: 0.1645  loss_box_reg: 0.2877  loss_mask: 0.1658  loss_rpn_cls: 0.03143  loss_rpn_loc: 0.09137    time: 0.2981  last_time: 0.2778  data_time: 0.0030  last_data_time: 0.0026   lr: 0.002  max_mem: 3227M
[03/19 22:24:23] d2.utils.events INFO:  eta: 0:10:12  iter: 1619  total_loss: 0.7999  loss_cls: 0.1661  loss_box_reg: 0.3168  loss_mask: 0.1734  loss_rpn_cls: 0.03451  loss_rpn_loc: 0.09559    time: 0.2981  last_time: 0.3034  data_time: 0.0032  last_data_time: 0.0032   lr: 0.002  max_mem: 3227M
[03/19 22:24:29] d2.utils.events INFO:  eta: 0:10:05  iter: 1639  total_loss: 0.7913  loss_cls: 0.1662  loss_box_reg: 0.3107  loss_mask: 0.1728  loss_rpn_cls: 0.03468  loss_rpn_loc: 0.09588    time: 0.2982  last_time: 0.2978  data_time: 0.0032  last_data_time: 0.0029   lr: 0.002  max_mem: 3227M
[03/19 22:24:35] d2.utils.events INFO:  eta: 0:09:59  iter: 1659  total_loss: 0.7648  loss_cls: 0.1648  loss_box_reg: 0.3186  loss_mask: 0.1745  loss_rpn_cls: 0.02732  loss_rpn_loc: 0.07422    time: 0.2983  last_time: 0.3037  data_time: 0.0032  last_data_time: 0.0035   lr: 0.002  max_mem: 3227M
[03/19 22:24:41] d2.utils.events INFO:  eta: 0:09:53  iter: 1679  total_loss: 0.811  loss_cls: 0.1575  loss_box_reg: 0.3265  loss_mask: 0.1697  loss_rpn_cls: 0.04184  loss_rpn_loc: 0.114    time: 0.2983  last_time: 0.2879  data_time: 0.0032  last_data_time: 0.0032   lr: 0.002  max_mem: 3227M
[03/19 22:24:47] d2.utils.events INFO:  eta: 0:09:46  iter: 1699  total_loss: 0.7954  loss_cls: 0.1533  loss_box_reg: 0.3258  loss_mask: 0.1708  loss_rpn_cls: 0.03657  loss_rpn_loc: 0.09611    time: 0.2984  last_time: 0.3059  data_time: 0.0031  last_data_time: 0.0030   lr: 0.002  max_mem: 3227M
[03/19 22:24:53] d2.utils.events INFO:  eta: 0:09:40  iter: 1719  total_loss: 0.7544  loss_cls: 0.1633  loss_box_reg: 0.3102  loss_mask: 0.1708  loss_rpn_cls: 0.03341  loss_rpn_loc: 0.08153    time: 0.2985  last_time: 0.2967  data_time: 0.0031  last_data_time: 0.0032   lr: 0.002  max_mem: 3227M
[03/19 22:25:00] d2.utils.events INFO:  eta: 0:09:34  iter: 1739  total_loss: 0.7852  loss_cls: 0.1528  loss_box_reg: 0.3312  loss_mask: 0.1703  loss_rpn_cls: 0.03516  loss_rpn_loc: 0.09973    time: 0.2985  last_time: 0.3136  data_time: 0.0032  last_data_time: 0.0033   lr: 0.002  max_mem: 3227M
[03/19 22:25:06] d2.utils.events INFO:  eta: 0:09:27  iter: 1759  total_loss: 0.7581  loss_cls: 0.144  loss_box_reg: 0.2998  loss_mask: 0.1621  loss_rpn_cls: 0.03197  loss_rpn_loc: 0.09588    time: 0.2985  last_time: 0.2904  data_time: 0.0034  last_data_time: 0.0035   lr: 0.002  max_mem: 3227M
[03/19 22:25:12] d2.utils.events INFO:  eta: 0:09:20  iter: 1779  total_loss: 0.7383  loss_cls: 0.1452  loss_box_reg: 0.2938  loss_mask: 0.1672  loss_rpn_cls: 0.03612  loss_rpn_loc: 0.1005    time: 0.2986  last_time: 0.2998  data_time: 0.0032  last_data_time: 0.0030   lr: 0.002  max_mem: 3227M
[03/19 22:25:16] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0001793.pth
[03/19 22:25:18] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 22:25:18] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 22:25:18] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:25:18] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 22:25:18] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 22:25:18] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 22:25:18] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0005 s/iter. Inference: 0.0268 s/iter. Eval: 0.0073 s/iter. Total: 0.0346 s/iter. ETA=0:00:00
[03/19 22:25:19] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.570175 (0.038012 s / iter per device, on 1 devices)
[03/19 22:25:19] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.027619 s / iter per device, on 1 devices)
[03/19 22:25:19] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 22:25:19] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 22:25:19] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 22:25:19] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 22:25:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:25:19] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:25:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:25:19] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 59.627 | 90.188 | 65.136 | 55.271 | 60.746 | 68.225 |
[03/19 22:25:19] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 75.218 | weed       | 44.037 |
[03/19 22:25:19] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 22:25:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 22:25:19] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:25:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:25:19] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 61.279 | 90.338 | 69.166 | 54.636 | 67.247 | 75.196 |
[03/19 22:25:19] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 78.040 | weed       | 44.518 |
[03/19 22:25:19] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 22:25:19] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 22:25:19] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:25:19] d2.evaluation.testing INFO: copypaste: 59.6272,90.1880,65.1365,55.2708,60.7457,68.2247
[03/19 22:25:19] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 22:25:19] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:25:19] d2.evaluation.testing INFO: copypaste: 61.2790,90.3383,69.1655,54.6356,67.2469,75.1957
[03/19 22:25:19] d2.utils.events INFO:  eta: 0:09:14  iter: 1799  total_loss: 0.7434  loss_cls: 0.147  loss_box_reg: 0.2938  loss_mask: 0.1594  loss_rpn_cls: 0.03811  loss_rpn_loc: 0.09185    time: 0.2986  last_time: 0.2814  data_time: 0.0034  last_data_time: 0.0039   lr: 0.002  max_mem: 3227M
[03/19 22:25:25] d2.utils.events INFO:  eta: 0:09:07  iter: 1819  total_loss: 0.762  loss_cls: 0.1468  loss_box_reg: 0.283  loss_mask: 0.1648  loss_rpn_cls: 0.04448  loss_rpn_loc: 0.1068    time: 0.2986  last_time: 0.2831  data_time: 0.0035  last_data_time: 0.0034   lr: 0.002  max_mem: 3227M
[03/19 22:25:31] d2.utils.events INFO:  eta: 0:09:00  iter: 1839  total_loss: 0.691  loss_cls: 0.1358  loss_box_reg: 0.2818  loss_mask: 0.1535  loss_rpn_cls: 0.03071  loss_rpn_loc: 0.0881    time: 0.2987  last_time: 0.3035  data_time: 0.0032  last_data_time: 0.0035   lr: 0.002  max_mem: 3227M
[03/19 22:25:37] d2.utils.events INFO:  eta: 0:08:53  iter: 1859  total_loss: 0.7972  loss_cls: 0.1552  loss_box_reg: 0.3082  loss_mask: 0.1791  loss_rpn_cls: 0.04944  loss_rpn_loc: 0.1009    time: 0.2987  last_time: 0.2775  data_time: 0.0031  last_data_time: 0.0033   lr: 0.002  max_mem: 3227M
[03/19 22:25:43] d2.utils.events INFO:  eta: 0:08:47  iter: 1879  total_loss: 0.7762  loss_cls: 0.1572  loss_box_reg: 0.3182  loss_mask: 0.1652  loss_rpn_cls: 0.02381  loss_rpn_loc: 0.08099    time: 0.2988  last_time: 0.3063  data_time: 0.0033  last_data_time: 0.0033   lr: 0.002  max_mem: 3227M
[03/19 22:25:49] d2.utils.events INFO:  eta: 0:08:41  iter: 1899  total_loss: 0.7678  loss_cls: 0.1554  loss_box_reg: 0.3237  loss_mask: 0.1731  loss_rpn_cls: 0.02462  loss_rpn_loc: 0.08483    time: 0.2989  last_time: 0.3110  data_time: 0.0031  last_data_time: 0.0033   lr: 0.002  max_mem: 3227M
[03/19 22:25:55] d2.utils.events INFO:  eta: 0:08:35  iter: 1919  total_loss: 0.752  loss_cls: 0.1472  loss_box_reg: 0.3107  loss_mask: 0.1658  loss_rpn_cls: 0.03269  loss_rpn_loc: 0.1032    time: 0.2989  last_time: 0.3024  data_time: 0.0032  last_data_time: 0.0032   lr: 0.002  max_mem: 3227M
[03/19 22:26:01] d2.utils.events INFO:  eta: 0:08:28  iter: 1939  total_loss: 0.7974  loss_cls: 0.1489  loss_box_reg: 0.3117  loss_mask: 0.1729  loss_rpn_cls: 0.04617  loss_rpn_loc: 0.09789    time: 0.2990  last_time: 0.3164  data_time: 0.0032  last_data_time: 0.0034   lr: 0.002  max_mem: 3227M
[03/19 22:26:07] d2.utils.events INFO:  eta: 0:08:22  iter: 1959  total_loss: 0.7059  loss_cls: 0.1504  loss_box_reg: 0.2881  loss_mask: 0.1611  loss_rpn_cls: 0.02677  loss_rpn_loc: 0.08118    time: 0.2990  last_time: 0.3034  data_time: 0.0033  last_data_time: 0.0033   lr: 0.002  max_mem: 3227M
[03/19 22:26:13] d2.utils.events INFO:  eta: 0:08:16  iter: 1979  total_loss: 0.706  loss_cls: 0.1388  loss_box_reg: 0.2804  loss_mask: 0.1586  loss_rpn_cls: 0.02868  loss_rpn_loc: 0.105    time: 0.2990  last_time: 0.3031  data_time: 0.0032  last_data_time: 0.0036   lr: 0.002  max_mem: 3227M
[03/19 22:26:19] d2.utils.events INFO:  eta: 0:08:09  iter: 1999  total_loss: 0.7019  loss_cls: 0.1473  loss_box_reg: 0.2881  loss_mask: 0.1608  loss_rpn_cls: 0.03084  loss_rpn_loc: 0.06639    time: 0.2991  last_time: 0.3057  data_time: 0.0031  last_data_time: 0.0035   lr: 0.002  max_mem: 3227M
[03/19 22:26:25] d2.utils.events INFO:  eta: 0:08:02  iter: 2019  total_loss: 0.6696  loss_cls: 0.1194  loss_box_reg: 0.2717  loss_mask: 0.1592  loss_rpn_cls: 0.03979  loss_rpn_loc: 0.07489    time: 0.2990  last_time: 0.2955  data_time: 0.0032  last_data_time: 0.0030   lr: 0.002  max_mem: 3227M
[03/19 22:26:31] d2.utils.events INFO:  eta: 0:07:56  iter: 2039  total_loss: 0.7586  loss_cls: 0.1521  loss_box_reg: 0.3017  loss_mask: 0.1691  loss_rpn_cls: 0.02638  loss_rpn_loc: 0.0922    time: 0.2991  last_time: 0.2978  data_time: 0.0030  last_data_time: 0.0028   lr: 0.002  max_mem: 3227M
[03/19 22:26:37] d2.utils.events INFO:  eta: 0:07:50  iter: 2059  total_loss: 0.7168  loss_cls: 0.1412  loss_box_reg: 0.2821  loss_mask: 0.167  loss_rpn_cls: 0.02709  loss_rpn_loc: 0.09921    time: 0.2991  last_time: 0.2916  data_time: 0.0032  last_data_time: 0.0035   lr: 0.002  max_mem: 3227M
[03/19 22:26:44] d2.utils.events INFO:  eta: 0:07:43  iter: 2079  total_loss: 0.669  loss_cls: 0.1265  loss_box_reg: 0.2812  loss_mask: 0.1629  loss_rpn_cls: 0.02417  loss_rpn_loc: 0.077    time: 0.2991  last_time: 0.3002  data_time: 0.0032  last_data_time: 0.0028   lr: 0.002  max_mem: 3227M
[03/19 22:26:47] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0002092.pth
[03/19 22:26:50] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 22:26:50] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 22:26:50] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:26:50] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 22:26:50] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 22:26:50] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 22:26:50] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0262 s/iter. Eval: 0.0049 s/iter. Total: 0.0315 s/iter. ETA=0:00:00
[03/19 22:26:51] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.528408 (0.035227 s / iter per device, on 1 devices)
[03/19 22:26:51] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.026961 s / iter per device, on 1 devices)
[03/19 22:26:51] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 22:26:51] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 22:26:51] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 22:26:51] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 22:26:51] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:26:51] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:26:51] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:26:51] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 62.986 | 91.258 | 68.432 | 58.465 | 64.552 | 76.203 |
[03/19 22:26:51] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 79.945 | weed       | 46.027 |
[03/19 22:26:51] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 22:26:51] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:26:51] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:26:51] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:26:51] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 65.354 | 91.304 | 73.810 | 58.704 | 69.938 | 77.426 |
[03/19 22:26:51] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 82.523 | weed       | 48.186 |
[03/19 22:26:51] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 22:26:51] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 22:26:51] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:26:51] d2.evaluation.testing INFO: copypaste: 62.9863,91.2583,68.4322,58.4648,64.5524,76.2034
[03/19 22:26:51] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 22:26:51] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:26:51] d2.evaluation.testing INFO: copypaste: 65.3544,91.3042,73.8102,58.7036,69.9384,77.4257
[03/19 22:26:51] d2.utils.events INFO:  eta: 0:07:37  iter: 2099  total_loss: 0.7454  loss_cls: 0.146  loss_box_reg: 0.2915  loss_mask: 0.1644  loss_rpn_cls: 0.03055  loss_rpn_loc: 0.08653    time: 0.2991  last_time: 0.3139  data_time: 0.0031  last_data_time: 0.0035   lr: 0.002  max_mem: 3227M
[03/19 22:26:57] d2.utils.events INFO:  eta: 0:07:31  iter: 2119  total_loss: 0.7445  loss_cls: 0.1421  loss_box_reg: 0.2823  loss_mask: 0.1638  loss_rpn_cls: 0.03052  loss_rpn_loc: 0.08433    time: 0.2991  last_time: 0.2997  data_time: 0.0034  last_data_time: 0.0032   lr: 0.002  max_mem: 3227M
[03/19 22:27:03] d2.utils.events INFO:  eta: 0:07:25  iter: 2139  total_loss: 0.7027  loss_cls: 0.1348  loss_box_reg: 0.2674  loss_mask: 0.1576  loss_rpn_cls: 0.03097  loss_rpn_loc: 0.09455    time: 0.2992  last_time: 0.3019  data_time: 0.0033  last_data_time: 0.0034   lr: 0.002  max_mem: 3227M
[03/19 22:27:09] d2.utils.events INFO:  eta: 0:07:19  iter: 2159  total_loss: 0.7216  loss_cls: 0.1456  loss_box_reg: 0.2933  loss_mask: 0.1613  loss_rpn_cls: 0.02639  loss_rpn_loc: 0.08522    time: 0.2992  last_time: 0.3156  data_time: 0.0034  last_data_time: 0.0036   lr: 0.002  max_mem: 3227M
[03/19 22:27:15] d2.utils.events INFO:  eta: 0:07:12  iter: 2179  total_loss: 0.6767  loss_cls: 0.1334  loss_box_reg: 0.2834  loss_mask: 0.1589  loss_rpn_cls: 0.02384  loss_rpn_loc: 0.07569    time: 0.2993  last_time: 0.3151  data_time: 0.0034  last_data_time: 0.0033   lr: 0.002  max_mem: 3227M
[03/19 22:27:21] d2.utils.events INFO:  eta: 0:07:07  iter: 2199  total_loss: 0.6798  loss_cls: 0.1242  loss_box_reg: 0.2845  loss_mask: 0.1576  loss_rpn_cls: 0.02902  loss_rpn_loc: 0.083    time: 0.2993  last_time: 0.3098  data_time: 0.0031  last_data_time: 0.0034   lr: 0.002  max_mem: 3227M
[03/19 22:27:27] d2.utils.events INFO:  eta: 0:07:00  iter: 2219  total_loss: 0.7291  loss_cls: 0.1406  loss_box_reg: 0.2797  loss_mask: 0.1604  loss_rpn_cls: 0.02734  loss_rpn_loc: 0.09709    time: 0.2993  last_time: 0.2969  data_time: 0.0035  last_data_time: 0.0032   lr: 0.002  max_mem: 3227M
[03/19 22:27:33] d2.utils.events INFO:  eta: 0:06:54  iter: 2239  total_loss: 0.7186  loss_cls: 0.1284  loss_box_reg: 0.2905  loss_mask: 0.1665  loss_rpn_cls: 0.03058  loss_rpn_loc: 0.09925    time: 0.2993  last_time: 0.2843  data_time: 0.0033  last_data_time: 0.0035   lr: 0.002  max_mem: 3227M
[03/19 22:27:39] d2.utils.events INFO:  eta: 0:06:48  iter: 2259  total_loss: 0.7397  loss_cls: 0.1439  loss_box_reg: 0.2994  loss_mask: 0.1655  loss_rpn_cls: 0.0257  loss_rpn_loc: 0.09135    time: 0.2994  last_time: 0.3089  data_time: 0.0030  last_data_time: 0.0027   lr: 0.002  max_mem: 3227M
[03/19 22:27:45] d2.utils.events INFO:  eta: 0:06:42  iter: 2279  total_loss: 0.7167  loss_cls: 0.1326  loss_box_reg: 0.2863  loss_mask: 0.1595  loss_rpn_cls: 0.03343  loss_rpn_loc: 0.09121    time: 0.2994  last_time: 0.3020  data_time: 0.0031  last_data_time: 0.0030   lr: 0.002  max_mem: 3227M
[03/19 22:27:51] d2.utils.events INFO:  eta: 0:06:36  iter: 2299  total_loss: 0.6676  loss_cls: 0.13  loss_box_reg: 0.2655  loss_mask: 0.1518  loss_rpn_cls: 0.02712  loss_rpn_loc: 0.09253    time: 0.2995  last_time: 0.3035  data_time: 0.0030  last_data_time: 0.0029   lr: 0.002  max_mem: 3227M
[03/19 22:27:58] d2.utils.events INFO:  eta: 0:06:29  iter: 2319  total_loss: 0.6801  loss_cls: 0.1364  loss_box_reg: 0.2703  loss_mask: 0.1615  loss_rpn_cls: 0.02048  loss_rpn_loc: 0.08739    time: 0.2996  last_time: 0.3089  data_time: 0.0032  last_data_time: 0.0030   lr: 0.002  max_mem: 3227M
[03/19 22:28:04] d2.utils.events INFO:  eta: 0:06:23  iter: 2339  total_loss: 0.6694  loss_cls: 0.1274  loss_box_reg: 0.2642  loss_mask: 0.1531  loss_rpn_cls: 0.03317  loss_rpn_loc: 0.07745    time: 0.2996  last_time: 0.3107  data_time: 0.0030  last_data_time: 0.0032   lr: 0.002  max_mem: 3227M
[03/19 22:28:10] d2.utils.events INFO:  eta: 0:06:17  iter: 2359  total_loss: 0.6701  loss_cls: 0.1356  loss_box_reg: 0.2806  loss_mask: 0.1611  loss_rpn_cls: 0.02514  loss_rpn_loc: 0.08036    time: 0.2997  last_time: 0.3069  data_time: 0.0030  last_data_time: 0.0031   lr: 0.002  max_mem: 3227M
[03/19 22:28:16] d2.utils.events INFO:  eta: 0:06:11  iter: 2379  total_loss: 0.6444  loss_cls: 0.1333  loss_box_reg: 0.2733  loss_mask: 0.1533  loss_rpn_cls: 0.02586  loss_rpn_loc: 0.07822    time: 0.2997  last_time: 0.2937  data_time: 0.0030  last_data_time: 0.0032   lr: 0.002  max_mem: 3227M
[03/19 22:28:20] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0002391.pth
[03/19 22:28:22] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 22:28:22] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 22:28:22] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:28:22] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 22:28:22] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 22:28:22] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 22:28:23] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0260 s/iter. Eval: 0.0048 s/iter. Total: 0.0312 s/iter. ETA=0:00:00
[03/19 22:28:23] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.516145 (0.034410 s / iter per device, on 1 devices)
[03/19 22:28:23] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.026588 s / iter per device, on 1 devices)
[03/19 22:28:23] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 22:28:23] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 22:28:23] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 22:28:23] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 22:28:23] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:28:23] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:28:23] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:28:23] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 61.862 | 89.256 | 70.625 | 56.573 | 66.134 | 72.918 |
[03/19 22:28:23] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 78.713 | weed       | 45.011 |
[03/19 22:28:23] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 22:28:23] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:28:23] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:28:23] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:28:23] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 62.482 | 90.193 | 68.546 | 54.912 | 70.730 | 77.426 |
[03/19 22:28:23] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 80.716 | weed       | 44.247 |
[03/19 22:28:23] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 22:28:23] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 22:28:23] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:28:23] d2.evaluation.testing INFO: copypaste: 61.8621,89.2555,70.6245,56.5732,66.1340,72.9176
[03/19 22:28:23] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 22:28:23] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:28:23] d2.evaluation.testing INFO: copypaste: 62.4818,90.1931,68.5462,54.9121,70.7297,77.4257
[03/19 22:28:23] d2.utils.events INFO:  eta: 0:06:05  iter: 2399  total_loss: 0.6136  loss_cls: 0.1194  loss_box_reg: 0.2592  loss_mask: 0.1538  loss_rpn_cls: 0.0206  loss_rpn_loc: 0.07585    time: 0.2997  last_time: 0.2859  data_time: 0.0029  last_data_time: 0.0029   lr: 0.002  max_mem: 3227M
[03/19 22:28:29] d2.utils.events INFO:  eta: 0:05:59  iter: 2419  total_loss: 0.7019  loss_cls: 0.1395  loss_box_reg: 0.2715  loss_mask: 0.1597  loss_rpn_cls: 0.02982  loss_rpn_loc: 0.09152    time: 0.2997  last_time: 0.3017  data_time: 0.0031  last_data_time: 0.0032   lr: 0.002  max_mem: 3227M
[03/19 22:28:35] d2.utils.events INFO:  eta: 0:05:53  iter: 2439  total_loss: 0.7003  loss_cls: 0.1408  loss_box_reg: 0.2851  loss_mask: 0.1665  loss_rpn_cls: 0.0255  loss_rpn_loc: 0.08509    time: 0.2997  last_time: 0.3062  data_time: 0.0031  last_data_time: 0.0031   lr: 0.002  max_mem: 3227M
[03/19 22:28:41] d2.utils.events INFO:  eta: 0:05:47  iter: 2459  total_loss: 0.6805  loss_cls: 0.1318  loss_box_reg: 0.2636  loss_mask: 0.1617  loss_rpn_cls: 0.02743  loss_rpn_loc: 0.09502    time: 0.2998  last_time: 0.3098  data_time: 0.0030  last_data_time: 0.0031   lr: 0.002  max_mem: 3227M
[03/19 22:28:47] d2.utils.events INFO:  eta: 0:05:40  iter: 2479  total_loss: 0.6412  loss_cls: 0.1196  loss_box_reg: 0.2647  loss_mask: 0.1535  loss_rpn_cls: 0.02161  loss_rpn_loc: 0.06935    time: 0.2998  last_time: 0.3138  data_time: 0.0032  last_data_time: 0.0034   lr: 0.002  max_mem: 3228M
[03/19 22:28:53] d2.utils.events INFO:  eta: 0:05:34  iter: 2499  total_loss: 0.6865  loss_cls: 0.1308  loss_box_reg: 0.2754  loss_mask: 0.157  loss_rpn_cls: 0.03079  loss_rpn_loc: 0.07871    time: 0.2998  last_time: 0.3111  data_time: 0.0032  last_data_time: 0.0034   lr: 0.002  max_mem: 3228M
[03/19 22:28:59] d2.utils.events INFO:  eta: 0:05:28  iter: 2519  total_loss: 0.6595  loss_cls: 0.1293  loss_box_reg: 0.2776  loss_mask: 0.1506  loss_rpn_cls: 0.02523  loss_rpn_loc: 0.07468    time: 0.2999  last_time: 0.3111  data_time: 0.0034  last_data_time: 0.0031   lr: 0.002  max_mem: 3228M
[03/19 22:29:05] d2.utils.events INFO:  eta: 0:05:22  iter: 2539  total_loss: 0.6411  loss_cls: 0.1101  loss_box_reg: 0.2772  loss_mask: 0.1549  loss_rpn_cls: 0.02623  loss_rpn_loc: 0.09573    time: 0.2999  last_time: 0.2728  data_time: 0.0033  last_data_time: 0.0035   lr: 0.002  max_mem: 3228M
[03/19 22:29:11] d2.utils.events INFO:  eta: 0:05:16  iter: 2559  total_loss: 0.6469  loss_cls: 0.1111  loss_box_reg: 0.2645  loss_mask: 0.1537  loss_rpn_cls: 0.0261  loss_rpn_loc: 0.07469    time: 0.2999  last_time: 0.2898  data_time: 0.0035  last_data_time: 0.0034   lr: 0.002  max_mem: 3228M
[03/19 22:29:17] d2.utils.events INFO:  eta: 0:05:10  iter: 2579  total_loss: 0.6602  loss_cls: 0.1144  loss_box_reg: 0.2691  loss_mask: 0.1601  loss_rpn_cls: 0.02979  loss_rpn_loc: 0.08642    time: 0.2999  last_time: 0.3071  data_time: 0.0031  last_data_time: 0.0031   lr: 0.002  max_mem: 3228M
[03/19 22:29:23] d2.utils.events INFO:  eta: 0:05:04  iter: 2599  total_loss: 0.6275  loss_cls: 0.1156  loss_box_reg: 0.2593  loss_mask: 0.1444  loss_rpn_cls: 0.01923  loss_rpn_loc: 0.07881    time: 0.2999  last_time: 0.3072  data_time: 0.0031  last_data_time: 0.0031   lr: 0.002  max_mem: 3228M
[03/19 22:29:30] d2.utils.events INFO:  eta: 0:04:58  iter: 2619  total_loss: 0.6682  loss_cls: 0.1182  loss_box_reg: 0.2687  loss_mask: 0.1577  loss_rpn_cls: 0.02042  loss_rpn_loc: 0.09105    time: 0.3000  last_time: 0.3014  data_time: 0.0031  last_data_time: 0.0033   lr: 0.002  max_mem: 3228M
[03/19 22:29:36] d2.utils.events INFO:  eta: 0:04:52  iter: 2639  total_loss: 0.7106  loss_cls: 0.1304  loss_box_reg: 0.277  loss_mask: 0.1737  loss_rpn_cls: 0.03667  loss_rpn_loc: 0.08668    time: 0.3000  last_time: 0.2851  data_time: 0.0032  last_data_time: 0.0033   lr: 0.002  max_mem: 3228M
[03/19 22:29:42] d2.utils.events INFO:  eta: 0:04:46  iter: 2659  total_loss: 0.6386  loss_cls: 0.1112  loss_box_reg: 0.2628  loss_mask: 0.1585  loss_rpn_cls: 0.02914  loss_rpn_loc: 0.07617    time: 0.3001  last_time: 0.3006  data_time: 0.0031  last_data_time: 0.0031   lr: 0.002  max_mem: 3228M
[03/19 22:29:48] d2.utils.events INFO:  eta: 0:04:40  iter: 2679  total_loss: 0.6322  loss_cls: 0.1027  loss_box_reg: 0.2484  loss_mask: 0.1569  loss_rpn_cls: 0.02272  loss_rpn_loc: 0.0677    time: 0.3002  last_time: 0.3116  data_time: 0.0031  last_data_time: 0.0036   lr: 0.002  max_mem: 3228M
[03/19 22:29:52] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0002690.pth
[03/19 22:29:54] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 22:29:54] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 22:29:54] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:29:54] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 22:29:54] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 22:29:54] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 22:29:55] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0263 s/iter. Eval: 0.0052 s/iter. Total: 0.0319 s/iter. ETA=0:00:00
[03/19 22:29:55] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.533299 (0.035553 s / iter per device, on 1 devices)
[03/19 22:29:55] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.027328 s / iter per device, on 1 devices)
[03/19 22:29:55] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 22:29:55] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 22:29:55] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 22:29:55] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 22:29:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:29:55] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:29:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:29:55] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 61.041 | 89.550 | 67.144 | 56.013 | 67.249 | 73.381 |
[03/19 22:29:55] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 78.713 | weed       | 43.369 |
[03/19 22:29:55] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 22:29:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:29:55] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:29:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:29:55] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 62.978 | 89.902 | 68.171 | 56.883 | 71.719 | 77.856 |
[03/19 22:29:55] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 81.811 | weed       | 44.145 |
[03/19 22:29:55] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 22:29:55] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 22:29:55] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:29:55] d2.evaluation.testing INFO: copypaste: 61.0409,89.5499,67.1440,56.0131,67.2486,73.3812
[03/19 22:29:55] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 22:29:55] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:29:55] d2.evaluation.testing INFO: copypaste: 62.9779,89.9015,68.1707,56.8834,71.7192,77.8557
[03/19 22:29:55] d2.utils.events INFO:  eta: 0:04:33  iter: 2699  total_loss: 0.7005  loss_cls: 0.1279  loss_box_reg: 0.2977  loss_mask: 0.1574  loss_rpn_cls: 0.02633  loss_rpn_loc: 0.08558    time: 0.3002  last_time: 0.2666  data_time: 0.0030  last_data_time: 0.0028   lr: 0.002  max_mem: 3228M
[03/19 22:30:02] d2.utils.events INFO:  eta: 0:04:27  iter: 2719  total_loss: 0.6184  loss_cls: 0.1203  loss_box_reg: 0.2644  loss_mask: 0.1592  loss_rpn_cls: 0.02194  loss_rpn_loc: 0.06557    time: 0.3004  last_time: 0.2978  data_time: 0.0032  last_data_time: 0.0032   lr: 0.002  max_mem: 3228M
[03/19 22:30:08] d2.utils.events INFO:  eta: 0:04:21  iter: 2739  total_loss: 0.6337  loss_cls: 0.1091  loss_box_reg: 0.2525  loss_mask: 0.1503  loss_rpn_cls: 0.02452  loss_rpn_loc: 0.07971    time: 0.3004  last_time: 0.3042  data_time: 0.0031  last_data_time: 0.0028   lr: 0.002  max_mem: 3228M
[03/19 22:30:14] d2.utils.events INFO:  eta: 0:04:15  iter: 2759  total_loss: 0.6272  loss_cls: 0.1205  loss_box_reg: 0.2616  loss_mask: 0.1536  loss_rpn_cls: 0.01926  loss_rpn_loc: 0.07913    time: 0.3006  last_time: 0.3110  data_time: 0.0032  last_data_time: 0.0031   lr: 0.002  max_mem: 3228M
[03/19 22:30:21] d2.utils.events INFO:  eta: 0:04:09  iter: 2779  total_loss: 0.6479  loss_cls: 0.1247  loss_box_reg: 0.2645  loss_mask: 0.1501  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.07517    time: 0.3007  last_time: 0.5454  data_time: 0.0031  last_data_time: 0.0029   lr: 0.002  max_mem: 3228M
[03/19 22:30:27] d2.utils.events INFO:  eta: 0:04:03  iter: 2799  total_loss: 0.6403  loss_cls: 0.115  loss_box_reg: 0.2579  loss_mask: 0.1594  loss_rpn_cls: 0.02244  loss_rpn_loc: 0.07361    time: 0.3007  last_time: 0.3807  data_time: 0.0033  last_data_time: 0.0039   lr: 0.002  max_mem: 3228M
[03/19 22:30:33] d2.utils.events INFO:  eta: 0:03:57  iter: 2819  total_loss: 0.6125  loss_cls: 0.1155  loss_box_reg: 0.252  loss_mask: 0.1438  loss_rpn_cls: 0.02002  loss_rpn_loc: 0.06899    time: 0.3008  last_time: 0.3070  data_time: 0.0034  last_data_time: 0.0033   lr: 0.002  max_mem: 3228M
[03/19 22:30:39] d2.utils.events INFO:  eta: 0:03:51  iter: 2839  total_loss: 0.6181  loss_cls: 0.1052  loss_box_reg: 0.2503  loss_mask: 0.1574  loss_rpn_cls: 0.02149  loss_rpn_loc: 0.08264    time: 0.3008  last_time: 0.2886  data_time: 0.0033  last_data_time: 0.0032   lr: 0.002  max_mem: 3228M
[03/19 22:30:45] d2.utils.events INFO:  eta: 0:03:45  iter: 2859  total_loss: 0.6556  loss_cls: 0.1093  loss_box_reg: 0.2603  loss_mask: 0.1486  loss_rpn_cls: 0.02698  loss_rpn_loc: 0.08844    time: 0.3008  last_time: 0.2991  data_time: 0.0033  last_data_time: 0.0035   lr: 0.002  max_mem: 3228M
[03/19 22:30:51] d2.utils.events INFO:  eta: 0:03:39  iter: 2879  total_loss: 0.6104  loss_cls: 0.1133  loss_box_reg: 0.26  loss_mask: 0.1568  loss_rpn_cls: 0.02239  loss_rpn_loc: 0.08034    time: 0.3008  last_time: 0.3109  data_time: 0.0032  last_data_time: 0.0032   lr: 0.002  max_mem: 3228M
[03/19 22:30:57] d2.utils.events INFO:  eta: 0:03:33  iter: 2899  total_loss: 0.5833  loss_cls: 0.09916  loss_box_reg: 0.2482  loss_mask: 0.1465  loss_rpn_cls: 0.01955  loss_rpn_loc: 0.0792    time: 0.3008  last_time: 0.2836  data_time: 0.0034  last_data_time: 0.0032   lr: 0.002  max_mem: 3228M
[03/19 22:31:03] d2.utils.events INFO:  eta: 0:03:27  iter: 2919  total_loss: 0.6469  loss_cls: 0.129  loss_box_reg: 0.2573  loss_mask: 0.1543  loss_rpn_cls: 0.03323  loss_rpn_loc: 0.07622    time: 0.3008  last_time: 0.3094  data_time: 0.0033  last_data_time: 0.0030   lr: 0.002  max_mem: 3228M
[03/19 22:31:09] d2.utils.events INFO:  eta: 0:03:21  iter: 2939  total_loss: 0.6645  loss_cls: 0.1243  loss_box_reg: 0.2794  loss_mask: 0.1562  loss_rpn_cls: 0.02654  loss_rpn_loc: 0.08278    time: 0.3009  last_time: 0.2995  data_time: 0.0033  last_data_time: 0.0033   lr: 0.002  max_mem: 3228M
[03/19 22:31:16] d2.utils.events INFO:  eta: 0:03:15  iter: 2959  total_loss: 0.6047  loss_cls: 0.1111  loss_box_reg: 0.2606  loss_mask: 0.1495  loss_rpn_cls: 0.01823  loss_rpn_loc: 0.06403    time: 0.3009  last_time: 0.3119  data_time: 0.0030  last_data_time: 0.0029   lr: 0.002  max_mem: 3228M
[03/19 22:31:22] d2.utils.events INFO:  eta: 0:03:08  iter: 2979  total_loss: 0.6657  loss_cls: 0.1056  loss_box_reg: 0.2603  loss_mask: 0.1555  loss_rpn_cls: 0.02944  loss_rpn_loc: 0.08411    time: 0.3009  last_time: 0.3050  data_time: 0.0031  last_data_time: 0.0034   lr: 0.002  max_mem: 3228M
[03/19 22:31:25] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0002989.pth
[03/19 22:31:28] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 22:31:28] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 22:31:28] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:31:28] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 22:31:28] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 22:31:28] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 22:31:28] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0261 s/iter. Eval: 0.0050 s/iter. Total: 0.0315 s/iter. ETA=0:00:00
[03/19 22:31:28] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.519988 (0.034666 s / iter per device, on 1 devices)
[03/19 22:31:28] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.026664 s / iter per device, on 1 devices)
[03/19 22:31:28] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 22:31:28] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 22:31:28] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 22:31:28] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 22:31:28] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:31:28] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:31:28] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:31:28] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 62.926 | 90.813 | 69.190 | 58.490 | 68.610 | 71.947 |
[03/19 22:31:28] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 80.366 | weed       | 45.486 |
[03/19 22:31:28] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 22:31:28] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:31:28] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:31:28] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:31:28] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 63.815 | 92.477 | 69.261 | 57.053 | 70.842 | 77.323 |
[03/19 22:31:28] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 82.005 | weed       | 45.625 |
[03/19 22:31:28] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 22:31:28] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 22:31:28] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:31:28] d2.evaluation.testing INFO: copypaste: 62.9257,90.8133,69.1898,58.4898,68.6095,71.9472
[03/19 22:31:28] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 22:31:28] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:31:28] d2.evaluation.testing INFO: copypaste: 63.8148,92.4770,69.2611,57.0534,70.8419,77.3226
[03/19 22:31:28] d2.utils.events INFO:  eta: 0:03:02  iter: 2999  total_loss: 0.5925  loss_cls: 0.09971  loss_box_reg: 0.2459  loss_mask: 0.146  loss_rpn_cls: 0.02663  loss_rpn_loc: 0.07699    time: 0.3008  last_time: 0.3017  data_time: 0.0032  last_data_time: 0.0034   lr: 0.002  max_mem: 3228M
[03/19 22:31:35] d2.utils.events INFO:  eta: 0:02:56  iter: 3019  total_loss: 0.5946  loss_cls: 0.1032  loss_box_reg: 0.2424  loss_mask: 0.1532  loss_rpn_cls: 0.02307  loss_rpn_loc: 0.0705    time: 0.3009  last_time: 0.3059  data_time: 0.0033  last_data_time: 0.0035   lr: 0.002  max_mem: 3228M
[03/19 22:31:41] d2.utils.events INFO:  eta: 0:02:50  iter: 3039  total_loss: 0.5914  loss_cls: 0.1073  loss_box_reg: 0.2435  loss_mask: 0.1431  loss_rpn_cls: 0.02211  loss_rpn_loc: 0.07731    time: 0.3009  last_time: 0.3175  data_time: 0.0031  last_data_time: 0.0031   lr: 0.002  max_mem: 3228M
[03/19 22:31:47] d2.utils.events INFO:  eta: 0:02:44  iter: 3059  total_loss: 0.6317  loss_cls: 0.1126  loss_box_reg: 0.2523  loss_mask: 0.1493  loss_rpn_cls: 0.02587  loss_rpn_loc: 0.06703    time: 0.3009  last_time: 0.2756  data_time: 0.0032  last_data_time: 0.0030   lr: 0.002  max_mem: 3228M
[03/19 22:31:53] d2.utils.events INFO:  eta: 0:02:38  iter: 3079  total_loss: 0.5705  loss_cls: 0.08885  loss_box_reg: 0.23  loss_mask: 0.1488  loss_rpn_cls: 0.02725  loss_rpn_loc: 0.06928    time: 0.3009  last_time: 0.2987  data_time: 0.0032  last_data_time: 0.0031   lr: 0.002  max_mem: 3228M
[03/19 22:31:59] d2.utils.events INFO:  eta: 0:02:32  iter: 3099  total_loss: 0.6155  loss_cls: 0.1149  loss_box_reg: 0.2502  loss_mask: 0.1455  loss_rpn_cls: 0.0215  loss_rpn_loc: 0.07968    time: 0.3010  last_time: 0.3122  data_time: 0.0033  last_data_time: 0.0032   lr: 0.002  max_mem: 3228M
[03/19 22:32:05] d2.utils.events INFO:  eta: 0:02:26  iter: 3119  total_loss: 0.6002  loss_cls: 0.1165  loss_box_reg: 0.252  loss_mask: 0.1513  loss_rpn_cls: 0.02034  loss_rpn_loc: 0.0786    time: 0.3010  last_time: 0.3047  data_time: 0.0035  last_data_time: 0.0036   lr: 0.002  max_mem: 3228M
[03/19 22:32:11] d2.utils.events INFO:  eta: 0:02:19  iter: 3139  total_loss: 0.6343  loss_cls: 0.1105  loss_box_reg: 0.2607  loss_mask: 0.1458  loss_rpn_cls: 0.02068  loss_rpn_loc: 0.07514    time: 0.3010  last_time: 0.2926  data_time: 0.0034  last_data_time: 0.0025   lr: 0.002  max_mem: 3228M
[03/19 22:32:17] d2.utils.events INFO:  eta: 0:02:13  iter: 3159  total_loss: 0.6041  loss_cls: 0.1128  loss_box_reg: 0.2387  loss_mask: 0.1503  loss_rpn_cls: 0.02507  loss_rpn_loc: 0.07072    time: 0.3010  last_time: 0.2987  data_time: 0.0034  last_data_time: 0.0035   lr: 0.002  max_mem: 3228M
[03/19 22:32:23] d2.utils.events INFO:  eta: 0:02:07  iter: 3179  total_loss: 0.5262  loss_cls: 0.08769  loss_box_reg: 0.2171  loss_mask: 0.1476  loss_rpn_cls: 0.02543  loss_rpn_loc: 0.07308    time: 0.3010  last_time: 0.3059  data_time: 0.0032  last_data_time: 0.0031   lr: 0.002  max_mem: 3228M
[03/19 22:32:29] d2.utils.events INFO:  eta: 0:02:01  iter: 3199  total_loss: 0.6263  loss_cls: 0.1029  loss_box_reg: 0.2369  loss_mask: 0.1526  loss_rpn_cls: 0.03044  loss_rpn_loc: 0.09255    time: 0.3010  last_time: 0.3195  data_time: 0.0031  last_data_time: 0.0033   lr: 0.002  max_mem: 3228M
[03/19 22:32:35] d2.utils.events INFO:  eta: 0:01:55  iter: 3219  total_loss: 0.6183  loss_cls: 0.1007  loss_box_reg: 0.2335  loss_mask: 0.1479  loss_rpn_cls: 0.02719  loss_rpn_loc: 0.07913    time: 0.3009  last_time: 0.3120  data_time: 0.0031  last_data_time: 0.0031   lr: 0.002  max_mem: 3228M
[03/19 22:32:41] d2.utils.events INFO:  eta: 0:01:49  iter: 3239  total_loss: 0.6128  loss_cls: 0.1066  loss_box_reg: 0.257  loss_mask: 0.1459  loss_rpn_cls: 0.01661  loss_rpn_loc: 0.06914    time: 0.3009  last_time: 0.2798  data_time: 0.0030  last_data_time: 0.0034   lr: 0.002  max_mem: 3228M
[03/19 22:32:47] d2.utils.events INFO:  eta: 0:01:43  iter: 3259  total_loss: 0.6114  loss_cls: 0.1067  loss_box_reg: 0.2423  loss_mask: 0.1548  loss_rpn_cls: 0.02203  loss_rpn_loc: 0.08588    time: 0.3009  last_time: 0.2966  data_time: 0.0031  last_data_time: 0.0029   lr: 0.002  max_mem: 3228M
[03/19 22:32:53] d2.utils.events INFO:  eta: 0:01:37  iter: 3279  total_loss: 0.6051  loss_cls: 0.1003  loss_box_reg: 0.2348  loss_mask: 0.149  loss_rpn_cls: 0.02514  loss_rpn_loc: 0.07607    time: 0.3009  last_time: 0.3045  data_time: 0.0031  last_data_time: 0.0028   lr: 0.002  max_mem: 3228M
[03/19 22:32:56] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0003288.pth
[03/19 22:33:00] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 22:33:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 22:33:00] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:33:00] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 22:33:00] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 22:33:00] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 22:33:00] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0263 s/iter. Eval: 0.0055 s/iter. Total: 0.0323 s/iter. ETA=0:00:00
[03/19 22:33:00] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.535040 (0.035669 s / iter per device, on 1 devices)
[03/19 22:33:00] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.026833 s / iter per device, on 1 devices)
[03/19 22:33:00] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 22:33:00] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 22:33:00] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 22:33:00] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 22:33:00] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:33:00] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:33:00] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:33:00] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 61.487 | 91.541 | 67.854 | 57.275 | 64.523 | 71.901 |
[03/19 22:33:00] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 77.756 | weed       | 45.218 |
[03/19 22:33:00] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 22:33:00] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[03/19 22:33:00] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:33:00] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:33:00] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 63.262 | 91.199 | 69.272 | 54.636 | 71.081 | 78.529 |
[03/19 22:33:00] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 80.703 | weed       | 45.820 |
[03/19 22:33:00] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 22:33:00] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 22:33:00] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:33:00] d2.evaluation.testing INFO: copypaste: 61.4868,91.5413,67.8537,57.2747,64.5233,71.9010
[03/19 22:33:00] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 22:33:00] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:33:00] d2.evaluation.testing INFO: copypaste: 63.2618,91.1992,69.2718,54.6356,71.0811,78.5290
[03/19 22:33:00] d2.utils.events INFO:  eta: 0:01:31  iter: 3299  total_loss: 0.5882  loss_cls: 0.1133  loss_box_reg: 0.2367  loss_mask: 0.1453  loss_rpn_cls: 0.01807  loss_rpn_loc: 0.07086    time: 0.3010  last_time: 0.2941  data_time: 0.0031  last_data_time: 0.0031   lr: 0.002  max_mem: 3228M
[03/19 22:33:07] d2.utils.events INFO:  eta: 0:01:24  iter: 3319  total_loss: 0.5888  loss_cls: 0.1182  loss_box_reg: 0.2503  loss_mask: 0.1466  loss_rpn_cls: 0.01889  loss_rpn_loc: 0.06313    time: 0.3012  last_time: 0.3753  data_time: 0.0032  last_data_time: 0.0036   lr: 0.002  max_mem: 3228M
[03/19 22:33:13] d2.utils.events INFO:  eta: 0:01:18  iter: 3339  total_loss: 0.5889  loss_cls: 0.1026  loss_box_reg: 0.2418  loss_mask: 0.1478  loss_rpn_cls: 0.02341  loss_rpn_loc: 0.06604    time: 0.3012  last_time: 0.3047  data_time: 0.0033  last_data_time: 0.0032   lr: 0.002  max_mem: 3228M
[03/19 22:33:19] d2.utils.events INFO:  eta: 0:01:12  iter: 3359  total_loss: 0.5823  loss_cls: 0.09621  loss_box_reg: 0.2526  loss_mask: 0.1468  loss_rpn_cls: 0.02134  loss_rpn_loc: 0.07077    time: 0.3012  last_time: 0.3110  data_time: 0.0035  last_data_time: 0.0031   lr: 0.002  max_mem: 3228M
[03/19 22:33:25] d2.utils.events INFO:  eta: 0:01:06  iter: 3379  total_loss: 0.5656  loss_cls: 0.09938  loss_box_reg: 0.2318  loss_mask: 0.1428  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.06612    time: 0.3012  last_time: 0.3053  data_time: 0.0031  last_data_time: 0.0030   lr: 0.002  max_mem: 3228M
[03/19 22:33:31] d2.utils.events INFO:  eta: 0:01:00  iter: 3399  total_loss: 0.6086  loss_cls: 0.1075  loss_box_reg: 0.2347  loss_mask: 0.1539  loss_rpn_cls: 0.02161  loss_rpn_loc: 0.0709    time: 0.3012  last_time: 0.2757  data_time: 0.0031  last_data_time: 0.0028   lr: 0.002  max_mem: 3228M
[03/19 22:33:37] d2.utils.events INFO:  eta: 0:00:54  iter: 3419  total_loss: 0.6039  loss_cls: 0.08472  loss_box_reg: 0.2484  loss_mask: 0.1543  loss_rpn_cls: 0.02531  loss_rpn_loc: 0.07916    time: 0.3012  last_time: 0.3113  data_time: 0.0030  last_data_time: 0.0033   lr: 0.002  max_mem: 3228M
[03/19 22:33:43] d2.utils.events INFO:  eta: 0:00:48  iter: 3439  total_loss: 0.6017  loss_cls: 0.0988  loss_box_reg: 0.2381  loss_mask: 0.1407  loss_rpn_cls: 0.0157  loss_rpn_loc: 0.08062    time: 0.3012  last_time: 0.2676  data_time: 0.0033  last_data_time: 0.0034   lr: 0.002  max_mem: 3228M
[03/19 22:33:49] d2.utils.events INFO:  eta: 0:00:42  iter: 3459  total_loss: 0.6034  loss_cls: 0.1017  loss_box_reg: 0.2296  loss_mask: 0.1492  loss_rpn_cls: 0.02628  loss_rpn_loc: 0.08193    time: 0.3012  last_time: 0.3012  data_time: 0.0033  last_data_time: 0.0032   lr: 0.002  max_mem: 3228M
[03/19 22:33:55] d2.utils.events INFO:  eta: 0:00:36  iter: 3479  total_loss: 0.5836  loss_cls: 0.1027  loss_box_reg: 0.2438  loss_mask: 0.1457  loss_rpn_cls: 0.02102  loss_rpn_loc: 0.07914    time: 0.3012  last_time: 0.2830  data_time: 0.0034  last_data_time: 0.0033   lr: 0.002  max_mem: 3228M
[03/19 22:34:01] d2.utils.events INFO:  eta: 0:00:30  iter: 3499  total_loss: 0.5267  loss_cls: 0.08535  loss_box_reg: 0.2156  loss_mask: 0.1428  loss_rpn_cls: 0.02264  loss_rpn_loc: 0.06458    time: 0.3011  last_time: 0.3056  data_time: 0.0031  last_data_time: 0.0030   lr: 0.002  max_mem: 3228M
[03/19 22:34:07] d2.utils.events INFO:  eta: 0:00:24  iter: 3519  total_loss: 0.6015  loss_cls: 0.1075  loss_box_reg: 0.2433  loss_mask: 0.1507  loss_rpn_cls: 0.019  loss_rpn_loc: 0.06998    time: 0.3011  last_time: 0.3031  data_time: 0.0036  last_data_time: 0.0035   lr: 0.002  max_mem: 3228M
[03/19 22:34:13] d2.utils.events INFO:  eta: 0:00:17  iter: 3539  total_loss: 0.5853  loss_cls: 0.07952  loss_box_reg: 0.2322  loss_mask: 0.1588  loss_rpn_cls: 0.02527  loss_rpn_loc: 0.07533    time: 0.3011  last_time: 0.3119  data_time: 0.0034  last_data_time: 0.0030   lr: 0.002  max_mem: 3228M
[03/19 22:34:19] d2.utils.events INFO:  eta: 0:00:11  iter: 3559  total_loss: 0.5648  loss_cls: 0.09716  loss_box_reg: 0.2278  loss_mask: 0.1403  loss_rpn_cls: 0.02106  loss_rpn_loc: 0.07348    time: 0.3011  last_time: 0.2936  data_time: 0.0036  last_data_time: 0.0037   lr: 0.002  max_mem: 3228M
[03/19 22:34:25] d2.utils.events INFO:  eta: 0:00:05  iter: 3579  total_loss: 0.5952  loss_cls: 0.1004  loss_box_reg: 0.2271  loss_mask: 0.1503  loss_rpn_cls: 0.02381  loss_rpn_loc: 0.07889    time: 0.3011  last_time: 0.3062  data_time: 0.0034  last_data_time: 0.0029   lr: 0.002  max_mem: 3228M
[03/19 22:34:27] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_0003587.pth
[03/19 22:34:31] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_final.pth
[03/19 22:34:31] d2.utils.events INFO:  eta: 0:00:00  iter: 3598  total_loss: 0.5566  loss_cls: 0.0891  loss_box_reg: 0.2235  loss_mask: 0.1487  loss_rpn_cls: 0.02112  loss_rpn_loc: 0.0805    time: 0.3010  last_time: 0.3145  data_time: 0.0032  last_data_time: 0.0038   lr: 0.002  max_mem: 3228M
[03/19 22:34:31] d2.engine.hooks INFO: Overall training speed: 3597 iterations in 0:18:02 (0.3010 s / it)
[03/19 22:34:31] d2.engine.hooks INFO: Total training time: 0:18:17 (0:00:14 on hooks)
[03/19 22:34:31] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 22:34:31] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 22:34:31] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:34:31] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 22:34:31] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 22:34:31] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 22:34:32] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0005 s/iter. Inference: 0.0260 s/iter. Eval: 0.0050 s/iter. Total: 0.0314 s/iter. ETA=0:00:00
[03/19 22:34:32] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.520864 (0.034724 s / iter per device, on 1 devices)
[03/19 22:34:32] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.026595 s / iter per device, on 1 devices)
[03/19 22:34:32] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 22:34:32] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 22:34:32] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 22:34:32] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 22:34:32] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:34:32] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:34:32] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:34:32] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 62.967 | 90.344 | 70.848 | 57.961 | 65.701 | 74.896 |
[03/19 22:34:32] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 80.492 | weed       | 45.443 |
[03/19 22:34:32] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 22:34:32] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:34:32] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:34:32] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:34:32] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 64.047 | 91.231 | 71.172 | 57.141 | 69.432 | 78.232 |
[03/19 22:34:32] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| potato     | 81.515 | weed       | 46.580 |
[03/19 22:34:32] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 22:34:32] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 22:34:32] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:34:32] d2.evaluation.testing INFO: copypaste: 62.9673,90.3437,70.8481,57.9605,65.7007,74.8963
[03/19 22:34:32] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 22:34:32] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:34:32] d2.evaluation.testing INFO: copypaste: 64.0474,91.2309,71.1719,57.1407,69.4322,78.2320
[03/19 22:35:20] detectron2 INFO: Rank of current process: 0. World size: 1
[03/19 22:35:20] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
numpy                            1.24.3
detectron2                       0.6 @/home/lu/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Ti (arch=8.6)
Driver version                   545.29.06
CUDA_HOME                        None - invalid!
Pillow                           10.2.0
torchvision                      0.17.1 @/home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision
torchvision arch flags           /home/lu/miniconda3/envs/detectron2/lib/python3.8/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[03/19 22:35:20] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[03/19 22:35:20] detectron2 INFO: Contents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[03/19 22:35:20] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_my_val
  TRAIN:
  - coco_my_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 640
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 512
  - 768
  MIN_SIZE_TRAIN_SAMPLING: range
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 2
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 299
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 3599
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 7000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 300
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/19 22:35:20] detectron2 INFO: Full config saved to ./output/config.yaml
[03/19 22:35:20] d2.utils.env INFO: Using a generated random seed 20744547
[03/19 22:35:21] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/19 22:35:21] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 22:35:21] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/19 22:35:21] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/19 22:35:21] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up - Total num: 54
[03/19 22:35:21] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.{bias, weight}[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[03/19 22:35:21] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/19 22:35:21] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from /home/lu/detectron2/potato/COCOformat/val.json
[03/19 22:35:21] d2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|   potato   | 82           |    weed    | 138          |
|            |              |            |              |
|   total    | 220          |            |              |[0m
[03/19 22:35:21] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[03/19 22:35:21] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/19 22:35:21] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[03/19 22:35:21] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[03/19 22:35:21] d2.evaluation.evaluator INFO: Start inference on 20 batches
[03/19 22:35:21] d2.evaluation.evaluator INFO: Inference done 11/20. Dataloading: 0.0004 s/iter. Inference: 0.0246 s/iter. Eval: 0.0013 s/iter. Total: 0.0263 s/iter. ETA=0:00:00
[03/19 22:35:22] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.438426 (0.029228 s / iter per device, on 1 devices)
[03/19 22:35:22] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.025462 s / iter per device, on 1 devices)
[03/19 22:35:22] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/19 22:35:22] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[03/19 22:35:22] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/19 22:35:22] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/19 22:35:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:35:22] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:35:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:35:22] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[03/19 22:35:22] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| potato     | 0.000 | weed       | 0.000 |
[03/19 22:35:22] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[03/19 22:35:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[03/19 22:35:22] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/19 22:35:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[03/19 22:35:22] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[03/19 22:35:22] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| potato     | 0.000 | weed       | 0.000 |
[03/19 22:35:22] d2.engine.defaults INFO: Evaluation results for coco_my_val in csv format:
[03/19 22:35:22] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/19 22:35:22] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:35:22] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000
[03/19 22:35:22] d2.evaluation.testing INFO: copypaste: Task: segm
[03/19 22:35:22] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/19 22:35:22] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000
